{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = pd.read_csv('resultado_pipeline_knn_20ng.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>mean_test_f1_macro</th>\n",
       "      <th>mean_test_f1_micro</th>\n",
       "      <th>mean_train_accuracy</th>\n",
       "      <th>mean_train_f1_macro</th>\n",
       "      <th>mean_train_f1_micro</th>\n",
       "      <th>param_knn__n_neighbors</th>\n",
       "      <th>...</th>\n",
       "      <th>split9_train_f1_macro</th>\n",
       "      <th>split9_train_f1_micro</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>std_test_f1_macro</th>\n",
       "      <th>std_test_f1_micro</th>\n",
       "      <th>std_train_accuracy</th>\n",
       "      <th>std_train_f1_macro</th>\n",
       "      <th>std_train_f1_micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3.409041</td>\n",
       "      <td>5.691012</td>\n",
       "      <td>0.807053</td>\n",
       "      <td>0.808039</td>\n",
       "      <td>0.807053</td>\n",
       "      <td>0.910750</td>\n",
       "      <td>0.911046</td>\n",
       "      <td>0.910750</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.912562</td>\n",
       "      <td>0.912374</td>\n",
       "      <td>0.681097</td>\n",
       "      <td>0.324248</td>\n",
       "      <td>0.014365</td>\n",
       "      <td>0.014074</td>\n",
       "      <td>0.014365</td>\n",
       "      <td>0.001729</td>\n",
       "      <td>0.001711</td>\n",
       "      <td>0.001729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.319197</td>\n",
       "      <td>5.782755</td>\n",
       "      <td>0.796624</td>\n",
       "      <td>0.794927</td>\n",
       "      <td>0.796624</td>\n",
       "      <td>0.883202</td>\n",
       "      <td>0.882334</td>\n",
       "      <td>0.883202</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.884618</td>\n",
       "      <td>0.885487</td>\n",
       "      <td>0.220604</td>\n",
       "      <td>0.320529</td>\n",
       "      <td>0.015315</td>\n",
       "      <td>0.016171</td>\n",
       "      <td>0.015315</td>\n",
       "      <td>0.002097</td>\n",
       "      <td>0.002118</td>\n",
       "      <td>0.002097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3.403280</td>\n",
       "      <td>5.604645</td>\n",
       "      <td>0.787697</td>\n",
       "      <td>0.784983</td>\n",
       "      <td>0.787697</td>\n",
       "      <td>0.863817</td>\n",
       "      <td>0.862267</td>\n",
       "      <td>0.863817</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.862450</td>\n",
       "      <td>0.864390</td>\n",
       "      <td>0.241654</td>\n",
       "      <td>0.175544</td>\n",
       "      <td>0.012002</td>\n",
       "      <td>0.012274</td>\n",
       "      <td>0.012002</td>\n",
       "      <td>0.001804</td>\n",
       "      <td>0.001920</td>\n",
       "      <td>0.001804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.332445</td>\n",
       "      <td>6.053687</td>\n",
       "      <td>0.780891</td>\n",
       "      <td>0.777799</td>\n",
       "      <td>0.780891</td>\n",
       "      <td>0.849371</td>\n",
       "      <td>0.847049</td>\n",
       "      <td>0.849371</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.845871</td>\n",
       "      <td>0.848298</td>\n",
       "      <td>0.268287</td>\n",
       "      <td>0.324597</td>\n",
       "      <td>0.013782</td>\n",
       "      <td>0.014188</td>\n",
       "      <td>0.013782</td>\n",
       "      <td>0.001920</td>\n",
       "      <td>0.002112</td>\n",
       "      <td>0.001920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3.320757</td>\n",
       "      <td>5.852653</td>\n",
       "      <td>0.776472</td>\n",
       "      <td>0.772068</td>\n",
       "      <td>0.776472</td>\n",
       "      <td>0.838303</td>\n",
       "      <td>0.835410</td>\n",
       "      <td>0.838303</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833991</td>\n",
       "      <td>0.837307</td>\n",
       "      <td>0.411605</td>\n",
       "      <td>0.328191</td>\n",
       "      <td>0.011824</td>\n",
       "      <td>0.012290</td>\n",
       "      <td>0.011824</td>\n",
       "      <td>0.001870</td>\n",
       "      <td>0.002043</td>\n",
       "      <td>0.001870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>3.225353</td>\n",
       "      <td>5.988369</td>\n",
       "      <td>0.773908</td>\n",
       "      <td>0.769008</td>\n",
       "      <td>0.773908</td>\n",
       "      <td>0.828531</td>\n",
       "      <td>0.825088</td>\n",
       "      <td>0.828531</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>0.824479</td>\n",
       "      <td>0.828182</td>\n",
       "      <td>0.283928</td>\n",
       "      <td>0.214553</td>\n",
       "      <td>0.008277</td>\n",
       "      <td>0.009025</td>\n",
       "      <td>0.008277</td>\n",
       "      <td>0.002227</td>\n",
       "      <td>0.002463</td>\n",
       "      <td>0.002227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>3.324570</td>\n",
       "      <td>5.772397</td>\n",
       "      <td>0.770638</td>\n",
       "      <td>0.765163</td>\n",
       "      <td>0.770638</td>\n",
       "      <td>0.823022</td>\n",
       "      <td>0.819061</td>\n",
       "      <td>0.823022</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.817181</td>\n",
       "      <td>0.821313</td>\n",
       "      <td>0.205924</td>\n",
       "      <td>0.275399</td>\n",
       "      <td>0.011523</td>\n",
       "      <td>0.012160</td>\n",
       "      <td>0.011523</td>\n",
       "      <td>0.001822</td>\n",
       "      <td>0.002028</td>\n",
       "      <td>0.001822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>3.407554</td>\n",
       "      <td>5.720251</td>\n",
       "      <td>0.766307</td>\n",
       "      <td>0.760362</td>\n",
       "      <td>0.766307</td>\n",
       "      <td>0.816471</td>\n",
       "      <td>0.812118</td>\n",
       "      <td>0.816471</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.811899</td>\n",
       "      <td>0.816210</td>\n",
       "      <td>0.327938</td>\n",
       "      <td>0.171587</td>\n",
       "      <td>0.011380</td>\n",
       "      <td>0.011800</td>\n",
       "      <td>0.011380</td>\n",
       "      <td>0.001176</td>\n",
       "      <td>0.001305</td>\n",
       "      <td>0.001176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>3.506751</td>\n",
       "      <td>6.040503</td>\n",
       "      <td>0.765423</td>\n",
       "      <td>0.759129</td>\n",
       "      <td>0.765423</td>\n",
       "      <td>0.810913</td>\n",
       "      <td>0.806304</td>\n",
       "      <td>0.810913</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0.805053</td>\n",
       "      <td>0.809734</td>\n",
       "      <td>0.351604</td>\n",
       "      <td>0.323949</td>\n",
       "      <td>0.008192</td>\n",
       "      <td>0.008842</td>\n",
       "      <td>0.008192</td>\n",
       "      <td>0.002630</td>\n",
       "      <td>0.002958</td>\n",
       "      <td>0.002630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>3.453612</td>\n",
       "      <td>5.739866</td>\n",
       "      <td>0.762241</td>\n",
       "      <td>0.755635</td>\n",
       "      <td>0.762241</td>\n",
       "      <td>0.804550</td>\n",
       "      <td>0.799511</td>\n",
       "      <td>0.804550</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>0.796440</td>\n",
       "      <td>0.801884</td>\n",
       "      <td>0.411851</td>\n",
       "      <td>0.330025</td>\n",
       "      <td>0.010778</td>\n",
       "      <td>0.011043</td>\n",
       "      <td>0.010778</td>\n",
       "      <td>0.002735</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>0.002735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>3.462854</td>\n",
       "      <td>5.627612</td>\n",
       "      <td>0.756585</td>\n",
       "      <td>0.749482</td>\n",
       "      <td>0.756585</td>\n",
       "      <td>0.797301</td>\n",
       "      <td>0.791576</td>\n",
       "      <td>0.797301</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.788660</td>\n",
       "      <td>0.794328</td>\n",
       "      <td>0.199542</td>\n",
       "      <td>0.271049</td>\n",
       "      <td>0.009477</td>\n",
       "      <td>0.009384</td>\n",
       "      <td>0.009477</td>\n",
       "      <td>0.002050</td>\n",
       "      <td>0.002260</td>\n",
       "      <td>0.002050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>3.450971</td>\n",
       "      <td>5.760654</td>\n",
       "      <td>0.751282</td>\n",
       "      <td>0.742680</td>\n",
       "      <td>0.751282</td>\n",
       "      <td>0.790094</td>\n",
       "      <td>0.783905</td>\n",
       "      <td>0.790094</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777667</td>\n",
       "      <td>0.784123</td>\n",
       "      <td>0.172884</td>\n",
       "      <td>0.253139</td>\n",
       "      <td>0.010183</td>\n",
       "      <td>0.010832</td>\n",
       "      <td>0.010183</td>\n",
       "      <td>0.003754</td>\n",
       "      <td>0.003875</td>\n",
       "      <td>0.003754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>3.377597</td>\n",
       "      <td>5.787493</td>\n",
       "      <td>0.749779</td>\n",
       "      <td>0.741042</td>\n",
       "      <td>0.749779</td>\n",
       "      <td>0.782414</td>\n",
       "      <td>0.775479</td>\n",
       "      <td>0.782414</td>\n",
       "      <td>35</td>\n",
       "      <td>...</td>\n",
       "      <td>0.771503</td>\n",
       "      <td>0.778236</td>\n",
       "      <td>0.246411</td>\n",
       "      <td>0.349512</td>\n",
       "      <td>0.008783</td>\n",
       "      <td>0.009707</td>\n",
       "      <td>0.008783</td>\n",
       "      <td>0.002984</td>\n",
       "      <td>0.003066</td>\n",
       "      <td>0.002984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>3.479773</td>\n",
       "      <td>5.920560</td>\n",
       "      <td>0.746420</td>\n",
       "      <td>0.737006</td>\n",
       "      <td>0.746420</td>\n",
       "      <td>0.774665</td>\n",
       "      <td>0.767155</td>\n",
       "      <td>0.774665</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>0.763464</td>\n",
       "      <td>0.771073</td>\n",
       "      <td>0.211481</td>\n",
       "      <td>0.332718</td>\n",
       "      <td>0.007163</td>\n",
       "      <td>0.007792</td>\n",
       "      <td>0.007163</td>\n",
       "      <td>0.002356</td>\n",
       "      <td>0.002525</td>\n",
       "      <td>0.002356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>3.425480</td>\n",
       "      <td>5.907164</td>\n",
       "      <td>0.740764</td>\n",
       "      <td>0.730478</td>\n",
       "      <td>0.740764</td>\n",
       "      <td>0.765955</td>\n",
       "      <td>0.757199</td>\n",
       "      <td>0.765955</td>\n",
       "      <td>49</td>\n",
       "      <td>...</td>\n",
       "      <td>0.752209</td>\n",
       "      <td>0.760769</td>\n",
       "      <td>0.395575</td>\n",
       "      <td>0.279441</td>\n",
       "      <td>0.007721</td>\n",
       "      <td>0.009500</td>\n",
       "      <td>0.007721</td>\n",
       "      <td>0.002925</td>\n",
       "      <td>0.003064</td>\n",
       "      <td>0.002925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>3.398968</td>\n",
       "      <td>5.900946</td>\n",
       "      <td>0.732544</td>\n",
       "      <td>0.721516</td>\n",
       "      <td>0.732544</td>\n",
       "      <td>0.758746</td>\n",
       "      <td>0.749205</td>\n",
       "      <td>0.758746</td>\n",
       "      <td>57</td>\n",
       "      <td>...</td>\n",
       "      <td>0.743977</td>\n",
       "      <td>0.752919</td>\n",
       "      <td>0.333166</td>\n",
       "      <td>0.258679</td>\n",
       "      <td>0.004256</td>\n",
       "      <td>0.003967</td>\n",
       "      <td>0.004256</td>\n",
       "      <td>0.002870</td>\n",
       "      <td>0.002951</td>\n",
       "      <td>0.002870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>3.358128</td>\n",
       "      <td>6.041729</td>\n",
       "      <td>0.721142</td>\n",
       "      <td>0.710354</td>\n",
       "      <td>0.721142</td>\n",
       "      <td>0.744163</td>\n",
       "      <td>0.734079</td>\n",
       "      <td>0.744163</td>\n",
       "      <td>73</td>\n",
       "      <td>...</td>\n",
       "      <td>0.727673</td>\n",
       "      <td>0.738102</td>\n",
       "      <td>0.247347</td>\n",
       "      <td>0.333129</td>\n",
       "      <td>0.008190</td>\n",
       "      <td>0.009936</td>\n",
       "      <td>0.008190</td>\n",
       "      <td>0.003015</td>\n",
       "      <td>0.003388</td>\n",
       "      <td>0.003015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>3.916759</td>\n",
       "      <td>5.847700</td>\n",
       "      <td>0.707884</td>\n",
       "      <td>0.696354</td>\n",
       "      <td>0.707884</td>\n",
       "      <td>0.728714</td>\n",
       "      <td>0.718290</td>\n",
       "      <td>0.728714</td>\n",
       "      <td>89</td>\n",
       "      <td>...</td>\n",
       "      <td>0.713866</td>\n",
       "      <td>0.724855</td>\n",
       "      <td>1.123247</td>\n",
       "      <td>0.320158</td>\n",
       "      <td>0.009619</td>\n",
       "      <td>0.009741</td>\n",
       "      <td>0.009619</td>\n",
       "      <td>0.002398</td>\n",
       "      <td>0.003069</td>\n",
       "      <td>0.002398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  mean_fit_time  mean_score_time  mean_test_accuracy  \\\n",
       "0            0       3.409041         5.691012            0.807053   \n",
       "1            1       3.319197         5.782755            0.796624   \n",
       "2            2       3.403280         5.604645            0.787697   \n",
       "3            3       3.332445         6.053687            0.780891   \n",
       "4            4       3.320757         5.852653            0.776472   \n",
       "5            5       3.225353         5.988369            0.773908   \n",
       "6            6       3.324570         5.772397            0.770638   \n",
       "7            7       3.407554         5.720251            0.766307   \n",
       "8            8       3.506751         6.040503            0.765423   \n",
       "9            9       3.453612         5.739866            0.762241   \n",
       "10          10       3.462854         5.627612            0.756585   \n",
       "11          11       3.450971         5.760654            0.751282   \n",
       "12          12       3.377597         5.787493            0.749779   \n",
       "13          13       3.479773         5.920560            0.746420   \n",
       "14          14       3.425480         5.907164            0.740764   \n",
       "15          15       3.398968         5.900946            0.732544   \n",
       "16          16       3.358128         6.041729            0.721142   \n",
       "17          17       3.916759         5.847700            0.707884   \n",
       "\n",
       "    mean_test_f1_macro  mean_test_f1_micro  mean_train_accuracy  \\\n",
       "0             0.808039            0.807053             0.910750   \n",
       "1             0.794927            0.796624             0.883202   \n",
       "2             0.784983            0.787697             0.863817   \n",
       "3             0.777799            0.780891             0.849371   \n",
       "4             0.772068            0.776472             0.838303   \n",
       "5             0.769008            0.773908             0.828531   \n",
       "6             0.765163            0.770638             0.823022   \n",
       "7             0.760362            0.766307             0.816471   \n",
       "8             0.759129            0.765423             0.810913   \n",
       "9             0.755635            0.762241             0.804550   \n",
       "10            0.749482            0.756585             0.797301   \n",
       "11            0.742680            0.751282             0.790094   \n",
       "12            0.741042            0.749779             0.782414   \n",
       "13            0.737006            0.746420             0.774665   \n",
       "14            0.730478            0.740764             0.765955   \n",
       "15            0.721516            0.732544             0.758746   \n",
       "16            0.710354            0.721142             0.744163   \n",
       "17            0.696354            0.707884             0.728714   \n",
       "\n",
       "    mean_train_f1_macro  mean_train_f1_micro  param_knn__n_neighbors  \\\n",
       "0              0.911046             0.910750                       3   \n",
       "1              0.882334             0.883202                       5   \n",
       "2              0.862267             0.863817                       7   \n",
       "3              0.847049             0.849371                       9   \n",
       "4              0.835410             0.838303                      11   \n",
       "5              0.825088             0.828531                      13   \n",
       "6              0.819061             0.823022                      15   \n",
       "7              0.812118             0.816471                      17   \n",
       "8              0.806304             0.810913                      19   \n",
       "9              0.799511             0.804550                      21   \n",
       "10             0.791576             0.797301                      25   \n",
       "11             0.783905             0.790094                      29   \n",
       "12             0.775479             0.782414                      35   \n",
       "13             0.767155             0.774665                      41   \n",
       "14             0.757199             0.765955                      49   \n",
       "15             0.749205             0.758746                      57   \n",
       "16             0.734079             0.744163                      73   \n",
       "17             0.718290             0.728714                      89   \n",
       "\n",
       "           ...         split9_train_f1_macro  split9_train_f1_micro  \\\n",
       "0          ...                      0.912562               0.912374   \n",
       "1          ...                      0.884618               0.885487   \n",
       "2          ...                      0.862450               0.864390   \n",
       "3          ...                      0.845871               0.848298   \n",
       "4          ...                      0.833991               0.837307   \n",
       "5          ...                      0.824479               0.828182   \n",
       "6          ...                      0.817181               0.821313   \n",
       "7          ...                      0.811899               0.816210   \n",
       "8          ...                      0.805053               0.809734   \n",
       "9          ...                      0.796440               0.801884   \n",
       "10         ...                      0.788660               0.794328   \n",
       "11         ...                      0.777667               0.784123   \n",
       "12         ...                      0.771503               0.778236   \n",
       "13         ...                      0.763464               0.771073   \n",
       "14         ...                      0.752209               0.760769   \n",
       "15         ...                      0.743977               0.752919   \n",
       "16         ...                      0.727673               0.738102   \n",
       "17         ...                      0.713866               0.724855   \n",
       "\n",
       "    std_fit_time  std_score_time  std_test_accuracy  std_test_f1_macro  \\\n",
       "0       0.681097        0.324248           0.014365           0.014074   \n",
       "1       0.220604        0.320529           0.015315           0.016171   \n",
       "2       0.241654        0.175544           0.012002           0.012274   \n",
       "3       0.268287        0.324597           0.013782           0.014188   \n",
       "4       0.411605        0.328191           0.011824           0.012290   \n",
       "5       0.283928        0.214553           0.008277           0.009025   \n",
       "6       0.205924        0.275399           0.011523           0.012160   \n",
       "7       0.327938        0.171587           0.011380           0.011800   \n",
       "8       0.351604        0.323949           0.008192           0.008842   \n",
       "9       0.411851        0.330025           0.010778           0.011043   \n",
       "10      0.199542        0.271049           0.009477           0.009384   \n",
       "11      0.172884        0.253139           0.010183           0.010832   \n",
       "12      0.246411        0.349512           0.008783           0.009707   \n",
       "13      0.211481        0.332718           0.007163           0.007792   \n",
       "14      0.395575        0.279441           0.007721           0.009500   \n",
       "15      0.333166        0.258679           0.004256           0.003967   \n",
       "16      0.247347        0.333129           0.008190           0.009936   \n",
       "17      1.123247        0.320158           0.009619           0.009741   \n",
       "\n",
       "    std_test_f1_micro  std_train_accuracy  std_train_f1_macro  \\\n",
       "0            0.014365            0.001729            0.001711   \n",
       "1            0.015315            0.002097            0.002118   \n",
       "2            0.012002            0.001804            0.001920   \n",
       "3            0.013782            0.001920            0.002112   \n",
       "4            0.011824            0.001870            0.002043   \n",
       "5            0.008277            0.002227            0.002463   \n",
       "6            0.011523            0.001822            0.002028   \n",
       "7            0.011380            0.001176            0.001305   \n",
       "8            0.008192            0.002630            0.002958   \n",
       "9            0.010778            0.002735            0.003030   \n",
       "10           0.009477            0.002050            0.002260   \n",
       "11           0.010183            0.003754            0.003875   \n",
       "12           0.008783            0.002984            0.003066   \n",
       "13           0.007163            0.002356            0.002525   \n",
       "14           0.007721            0.002925            0.003064   \n",
       "15           0.004256            0.002870            0.002951   \n",
       "16           0.008190            0.003015            0.003388   \n",
       "17           0.009619            0.002398            0.003069   \n",
       "\n",
       "    std_train_f1_micro  \n",
       "0             0.001729  \n",
       "1             0.002097  \n",
       "2             0.001804  \n",
       "3             0.001920  \n",
       "4             0.001870  \n",
       "5             0.002227  \n",
       "6             0.001822  \n",
       "7             0.001176  \n",
       "8             0.002630  \n",
       "9             0.002735  \n",
       "10            0.002050  \n",
       "11            0.003754  \n",
       "12            0.002984  \n",
       "13            0.002356  \n",
       "14            0.002925  \n",
       "15            0.002870  \n",
       "16            0.003015  \n",
       "17            0.002398  \n",
       "\n",
       "[18 rows x 82 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_test_accuracy: 0.807053 (0.014365) - mean_train_accuracy: 0.910750 (0.014365) with: \"{'knn__n_neighbors': 3}\"\n",
      "mean_test_accuracy: 0.796624 (0.015315) - mean_train_accuracy: 0.883202 (0.015315) with: \"{'knn__n_neighbors': 5}\"\n",
      "mean_test_accuracy: 0.787697 (0.012002) - mean_train_accuracy: 0.863817 (0.012002) with: \"{'knn__n_neighbors': 7}\"\n",
      "mean_test_accuracy: 0.780891 (0.013782) - mean_train_accuracy: 0.849371 (0.013782) with: \"{'knn__n_neighbors': 9}\"\n",
      "mean_test_accuracy: 0.776472 (0.011824) - mean_train_accuracy: 0.838303 (0.011824) with: \"{'knn__n_neighbors': 11}\"\n",
      "mean_test_accuracy: 0.773908 (0.008277) - mean_train_accuracy: 0.828531 (0.008277) with: \"{'knn__n_neighbors': 13}\"\n",
      "mean_test_accuracy: 0.770638 (0.011523) - mean_train_accuracy: 0.823022 (0.011523) with: \"{'knn__n_neighbors': 15}\"\n",
      "mean_test_accuracy: 0.766307 (0.011380) - mean_train_accuracy: 0.816471 (0.011380) with: \"{'knn__n_neighbors': 17}\"\n",
      "mean_test_accuracy: 0.765423 (0.008192) - mean_train_accuracy: 0.810913 (0.008192) with: \"{'knn__n_neighbors': 19}\"\n",
      "mean_test_accuracy: 0.762241 (0.010778) - mean_train_accuracy: 0.804550 (0.010778) with: \"{'knn__n_neighbors': 21}\"\n",
      "mean_test_accuracy: 0.756585 (0.009477) - mean_train_accuracy: 0.797301 (0.009477) with: \"{'knn__n_neighbors': 25}\"\n",
      "mean_test_accuracy: 0.751282 (0.010183) - mean_train_accuracy: 0.790094 (0.010183) with: \"{'knn__n_neighbors': 29}\"\n",
      "mean_test_accuracy: 0.749779 (0.008783) - mean_train_accuracy: 0.782414 (0.008783) with: \"{'knn__n_neighbors': 35}\"\n",
      "mean_test_accuracy: 0.746420 (0.007163) - mean_train_accuracy: 0.774665 (0.007163) with: \"{'knn__n_neighbors': 41}\"\n",
      "mean_test_accuracy: 0.740764 (0.007721) - mean_train_accuracy: 0.765955 (0.007721) with: \"{'knn__n_neighbors': 49}\"\n",
      "mean_test_accuracy: 0.732544 (0.004256) - mean_train_accuracy: 0.758746 (0.004256) with: \"{'knn__n_neighbors': 57}\"\n",
      "mean_test_accuracy: 0.721142 (0.008190) - mean_train_accuracy: 0.744163 (0.008190) with: \"{'knn__n_neighbors': 73}\"\n",
      "mean_test_accuracy: 0.707884 (0.009619) - mean_train_accuracy: 0.728714 (0.009619) with: \"{'knn__n_neighbors': 89}\"\n"
     ]
    }
   ],
   "source": [
    "means_test = resultados['mean_test_accuracy']\n",
    "std_test_acuracy = resultados['std_test_accuracy']\n",
    "means_train = resultados['mean_train_accuracy']\n",
    "std_train_acuracy = resultados['std_test_accuracy']\n",
    "params = resultados['params']\n",
    "\n",
    "for test, stdev_test, train, stdev_train, param in zip(means_test, std_test_acuracy, means_train, std_train_acuracy, params):\n",
    "    print(\"mean_test_accuracy: %f (%f) - mean_train_accuracy: %f (%f) with: %r\" %(test, stdev_test, train, stdev_train, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = pd.read_csv('resultado_pipeline_knn_classic3.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_test_accuracy: 0.946018 (0.006626) - mean_train_accuracy: 0.973502 (0.006626) with: \"{'knn__n_neighbors': 3}\"\n",
      "mean_test_accuracy: 0.947710 (0.007675) - mean_train_accuracy: 0.966393 (0.007675) with: \"{'knn__n_neighbors': 5}\"\n",
      "mean_test_accuracy: 0.951233 (0.007595) - mean_train_accuracy: 0.963762 (0.007595) with: \"{'knn__n_neighbors': 7}\"\n",
      "mean_test_accuracy: 0.950247 (0.008062) - mean_train_accuracy: 0.961914 (0.008062) with: \"{'knn__n_neighbors': 9}\"\n",
      "mean_test_accuracy: 0.949401 (0.010298) - mean_train_accuracy: 0.959377 (0.010298) with: \"{'knn__n_neighbors': 11}\"\n",
      "mean_test_accuracy: 0.949683 (0.009171) - mean_train_accuracy: 0.957717 (0.009171) with: \"{'knn__n_neighbors': 13}\"\n",
      "mean_test_accuracy: 0.949401 (0.008169) - mean_train_accuracy: 0.956949 (0.008169) with: \"{'knn__n_neighbors': 15}\"\n",
      "mean_test_accuracy: 0.947287 (0.009392) - mean_train_accuracy: 0.955603 (0.009392) with: \"{'knn__n_neighbors': 17}\"\n",
      "mean_test_accuracy: 0.947428 (0.008075) - mean_train_accuracy: 0.954115 (0.008075) with: \"{'knn__n_neighbors': 19}\"\n",
      "mean_test_accuracy: 0.946441 (0.008549) - mean_train_accuracy: 0.952564 (0.008549) with: \"{'knn__n_neighbors': 21}\"\n",
      "mean_test_accuracy: 0.945032 (0.009069) - mean_train_accuracy: 0.950763 (0.009069) with: \"{'knn__n_neighbors': 25}\"\n",
      "mean_test_accuracy: 0.941649 (0.009127) - mean_train_accuracy: 0.948242 (0.009127) with: \"{'knn__n_neighbors': 29}\"\n",
      "mean_test_accuracy: 0.940944 (0.010069) - mean_train_accuracy: 0.945173 (0.010069) with: \"{'knn__n_neighbors': 35}\"\n",
      "mean_test_accuracy: 0.936998 (0.008987) - mean_train_accuracy: 0.940428 (0.008987) with: \"{'knn__n_neighbors': 41}\"\n",
      "mean_test_accuracy: 0.931501 (0.009805) - mean_train_accuracy: 0.936090 (0.009805) with: \"{'knn__n_neighbors': 49}\"\n",
      "mean_test_accuracy: 0.929246 (0.009658) - mean_train_accuracy: 0.933161 (0.009658) with: \"{'knn__n_neighbors': 57}\"\n",
      "mean_test_accuracy: 0.923044 (0.010760) - mean_train_accuracy: 0.926975 (0.010760) with: \"{'knn__n_neighbors': 73}\"\n",
      "mean_test_accuracy: 0.916843 (0.010873) - mean_train_accuracy: 0.920367 (0.010873) with: \"{'knn__n_neighbors': 89}\"\n"
     ]
    }
   ],
   "source": [
    "means_test = resultados['mean_test_accuracy']\n",
    "std_test_acuracy = resultados['std_test_accuracy']\n",
    "means_train = resultados['mean_train_accuracy']\n",
    "std_train_acuracy = resultados['std_test_accuracy']\n",
    "params = resultados['params']\n",
    "\n",
    "for test, stdev_test, train, stdev_train, param in zip(means_test, std_test_acuracy, means_train, std_train_acuracy, params):\n",
    "    print(\"mean_test_accuracy: %f (%f) - mean_train_accuracy: %f (%f) with: %r\" %(test, stdev_test, train, stdev_train, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_test_accuracy: 0.852843 (0.049370) - mean_train_accuracy: 0.921217 (0.049370) with: \"{'knn__n_neighbors': 3}\"\n",
      "mean_test_accuracy: 0.869565 (0.038597) - mean_train_accuracy: 0.896696 (0.038597) with: \"{'knn__n_neighbors': 5}\"\n",
      "mean_test_accuracy: 0.866221 (0.039462) - mean_train_accuracy: 0.895953 (0.039462) with: \"{'knn__n_neighbors': 7}\"\n",
      "mean_test_accuracy: 0.852843 (0.050007) - mean_train_accuracy: 0.891503 (0.050007) with: \"{'knn__n_neighbors': 9}\"\n",
      "mean_test_accuracy: 0.852843 (0.067409) - mean_train_accuracy: 0.877369 (0.067409) with: \"{'knn__n_neighbors': 11}\"\n",
      "mean_test_accuracy: 0.846154 (0.078974) - mean_train_accuracy: 0.876244 (0.078974) with: \"{'knn__n_neighbors': 13}\"\n",
      "mean_test_accuracy: 0.842809 (0.084224) - mean_train_accuracy: 0.865108 (0.084224) with: \"{'knn__n_neighbors': 15}\"\n",
      "mean_test_accuracy: 0.819398 (0.085305) - mean_train_accuracy: 0.855448 (0.085305) with: \"{'knn__n_neighbors': 17}\"\n",
      "mean_test_accuracy: 0.819398 (0.080019) - mean_train_accuracy: 0.839085 (0.080019) with: \"{'knn__n_neighbors': 19}\"\n",
      "mean_test_accuracy: 0.809365 (0.079652) - mean_train_accuracy: 0.825716 (0.079652) with: \"{'knn__n_neighbors': 21}\"\n",
      "mean_test_accuracy: 0.785953 (0.071708) - mean_train_accuracy: 0.806787 (0.071708) with: \"{'knn__n_neighbors': 25}\"\n",
      "mean_test_accuracy: 0.762542 (0.064926) - mean_train_accuracy: 0.788214 (0.064926) with: \"{'knn__n_neighbors': 29}\"\n",
      "mean_test_accuracy: 0.765886 (0.063228) - mean_train_accuracy: 0.778905 (0.063228) with: \"{'knn__n_neighbors': 35}\"\n",
      "mean_test_accuracy: 0.725753 (0.062356) - mean_train_accuracy: 0.766658 (0.062356) with: \"{'knn__n_neighbors': 41}\"\n",
      "mean_test_accuracy: 0.729097 (0.065908) - mean_train_accuracy: 0.748417 (0.065908) with: \"{'knn__n_neighbors': 49}\"\n",
      "mean_test_accuracy: 0.695652 (0.070366) - mean_train_accuracy: 0.712370 (0.070366) with: \"{'knn__n_neighbors': 57}\"\n",
      "mean_test_accuracy: 0.635452 (0.072442) - mean_train_accuracy: 0.663334 (0.072442) with: \"{'knn__n_neighbors': 73}\"\n",
      "mean_test_accuracy: 0.622074 (0.076138) - mean_train_accuracy: 0.632100 (0.076138) with: \"{'knn__n_neighbors': 89}\"\n"
     ]
    }
   ],
   "source": [
    "resultados = pd.read_csv('resultado_pipeline_knn_CSTR.csv', sep=';')\n",
    "means_test = resultados['mean_test_accuracy']\n",
    "std_test_acuracy = resultados['std_test_accuracy']\n",
    "means_train = resultados['mean_train_accuracy']\n",
    "std_train_acuracy = resultados['std_test_accuracy']\n",
    "params = resultados['params']\n",
    "\n",
    "for test, stdev_test, train, stdev_train, param in zip(means_test, std_test_acuracy, means_train, std_train_acuracy, params):\n",
    "    print(\"mean_test_accuracy: %f (%f) - mean_train_accuracy: %f (%f) with: %r\" %(test, stdev_test, train, stdev_train, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_test_accuracy: 0.568072 (0.038125) - mean_train_accuracy: 0.785076 (0.038125) with: \"{'knn__n_neighbors': 3}\"\n",
      "mean_test_accuracy: 0.569880 (0.034833) - mean_train_accuracy: 0.729252 (0.034833) with: \"{'knn__n_neighbors': 5}\"\n",
      "mean_test_accuracy: 0.558434 (0.031601) - mean_train_accuracy: 0.682531 (0.031601) with: \"{'knn__n_neighbors': 7}\"\n",
      "mean_test_accuracy: 0.560843 (0.035003) - mean_train_accuracy: 0.654151 (0.035003) with: \"{'knn__n_neighbors': 9}\"\n",
      "mean_test_accuracy: 0.539759 (0.028012) - mean_train_accuracy: 0.633605 (0.028012) with: \"{'knn__n_neighbors': 11}\"\n",
      "mean_test_accuracy: 0.537952 (0.019973) - mean_train_accuracy: 0.611448 (0.019973) with: \"{'knn__n_neighbors': 13}\"\n",
      "mean_test_accuracy: 0.533735 (0.025551) - mean_train_accuracy: 0.600068 (0.025551) with: \"{'knn__n_neighbors': 15}\"\n",
      "mean_test_accuracy: 0.524699 (0.025275) - mean_train_accuracy: 0.584606 (0.025275) with: \"{'knn__n_neighbors': 17}\"\n",
      "mean_test_accuracy: 0.517470 (0.023007) - mean_train_accuracy: 0.571422 (0.023007) with: \"{'knn__n_neighbors': 19}\"\n",
      "mean_test_accuracy: 0.511446 (0.024819) - mean_train_accuracy: 0.564328 (0.024819) with: \"{'knn__n_neighbors': 21}\"\n",
      "mean_test_accuracy: 0.504217 (0.026494) - mean_train_accuracy: 0.542708 (0.026494) with: \"{'knn__n_neighbors': 25}\"\n",
      "mean_test_accuracy: 0.493373 (0.020619) - mean_train_accuracy: 0.528181 (0.020619) with: \"{'knn__n_neighbors': 29}\"\n",
      "mean_test_accuracy: 0.481928 (0.017180) - mean_train_accuracy: 0.510107 (0.017180) with: \"{'knn__n_neighbors': 35}\"\n",
      "mean_test_accuracy: 0.473494 (0.007990) - mean_train_accuracy: 0.496988 (0.007990) with: \"{'knn__n_neighbors': 41}\"\n",
      "mean_test_accuracy: 0.471687 (0.009891) - mean_train_accuracy: 0.485274 (0.009891) with: \"{'knn__n_neighbors': 49}\"\n",
      "mean_test_accuracy: 0.463253 (0.017037) - mean_train_accuracy: 0.477376 (0.017037) with: \"{'knn__n_neighbors': 57}\"\n",
      "mean_test_accuracy: 0.454217 (0.013300) - mean_train_accuracy: 0.464257 (0.013300) with: \"{'knn__n_neighbors': 73}\"\n",
      "mean_test_accuracy: 0.448795 (0.011626) - mean_train_accuracy: 0.454484 (0.011626) with: \"{'knn__n_neighbors': 89}\"\n"
     ]
    }
   ],
   "source": [
    "resultados = pd.read_csv('resultado_pipeline_knn_IrishEconomicSentiment.csv', sep=';')\n",
    "means_test = resultados['mean_test_accuracy']\n",
    "std_test_acuracy = resultados['std_test_accuracy']\n",
    "means_train = resultados['mean_train_accuracy']\n",
    "std_train_acuracy = resultados['std_test_accuracy']\n",
    "params = resultados['params']\n",
    "\n",
    "for test, stdev_test, train, stdev_train, param in zip(means_test, std_test_acuracy, means_train, std_train_acuracy, params):\n",
    "    print(\"mean_test_accuracy: %f (%f) - mean_train_accuracy: %f (%f) with: %r\" %(test, stdev_test, train, stdev_train, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_test_accuracy: 0.640875 (0.017330) - mean_train_accuracy: 0.829000 (0.017330) with: \"{'knn__n_neighbors': 3}\"\n",
      "mean_test_accuracy: 0.654375 (0.016510) - mean_train_accuracy: 0.784167 (0.016510) with: \"{'knn__n_neighbors': 5}\"\n",
      "mean_test_accuracy: 0.665250 (0.019412) - mean_train_accuracy: 0.767569 (0.019412) with: \"{'knn__n_neighbors': 7}\"\n",
      "mean_test_accuracy: 0.671500 (0.021034) - mean_train_accuracy: 0.762972 (0.021034) with: \"{'knn__n_neighbors': 9}\"\n",
      "mean_test_accuracy: 0.677250 (0.019572) - mean_train_accuracy: 0.757833 (0.019572) with: \"{'knn__n_neighbors': 11}\"\n",
      "mean_test_accuracy: 0.680125 (0.018887) - mean_train_accuracy: 0.752792 (0.018887) with: \"{'knn__n_neighbors': 13}\"\n",
      "mean_test_accuracy: 0.685000 (0.015988) - mean_train_accuracy: 0.750375 (0.015988) with: \"{'knn__n_neighbors': 15}\"\n",
      "mean_test_accuracy: 0.688625 (0.016426) - mean_train_accuracy: 0.749222 (0.016426) with: \"{'knn__n_neighbors': 17}\"\n",
      "mean_test_accuracy: 0.690500 (0.016528) - mean_train_accuracy: 0.747806 (0.016528) with: \"{'knn__n_neighbors': 19}\"\n",
      "mean_test_accuracy: 0.692625 (0.011772) - mean_train_accuracy: 0.748861 (0.011772) with: \"{'knn__n_neighbors': 21}\"\n",
      "mean_test_accuracy: 0.705500 (0.011486) - mean_train_accuracy: 0.751292 (0.011486) with: \"{'knn__n_neighbors': 25}\"\n",
      "mean_test_accuracy: 0.704875 (0.011353) - mean_train_accuracy: 0.752903 (0.011353) with: \"{'knn__n_neighbors': 29}\"\n",
      "mean_test_accuracy: 0.715500 (0.013302) - mean_train_accuracy: 0.750694 (0.013302) with: \"{'knn__n_neighbors': 35}\"\n",
      "mean_test_accuracy: 0.718625 (0.008356) - mean_train_accuracy: 0.751528 (0.008356) with: \"{'knn__n_neighbors': 41}\"\n",
      "mean_test_accuracy: 0.723250 (0.013089) - mean_train_accuracy: 0.752250 (0.013089) with: \"{'knn__n_neighbors': 49}\"\n",
      "mean_test_accuracy: 0.726125 (0.016877) - mean_train_accuracy: 0.752556 (0.016877) with: \"{'knn__n_neighbors': 57}\"\n",
      "mean_test_accuracy: 0.730500 (0.011028) - mean_train_accuracy: 0.757583 (0.011028) with: \"{'knn__n_neighbors': 73}\"\n",
      "mean_test_accuracy: 0.736375 (0.015273) - mean_train_accuracy: 0.760181 (0.015273) with: \"{'knn__n_neighbors': 89}\"\n"
     ]
    }
   ],
   "source": [
    "resultados = pd.read_csv('resultado_pipeline_knn_multi-domain-sentiment.csv', sep=';')\n",
    "means_test = resultados['mean_test_accuracy']\n",
    "std_test_acuracy = resultados['std_test_accuracy']\n",
    "means_train = resultados['mean_train_accuracy']\n",
    "std_train_acuracy = resultados['std_test_accuracy']\n",
    "params = resultados['params']\n",
    "\n",
    "for test, stdev_test, train, stdev_train, param in zip(means_test, std_test_acuracy, means_train, std_train_acuracy, params):\n",
    "    print(\"mean_test_accuracy: %f (%f) - mean_train_accuracy: %f (%f) with: %r\" %(test, stdev_test, train, stdev_train, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_test_accuracy: 0.766059 (0.007867) - mean_train_accuracy: 0.889575 (0.007867) with: \"{'knn__n_neighbors': 3}\"\n",
      "mean_test_accuracy: 0.784208 (0.011122) - mean_train_accuracy: 0.875132 (0.011122) with: \"{'knn__n_neighbors': 5}\"\n",
      "mean_test_accuracy: 0.789909 (0.009732) - mean_train_accuracy: 0.864637 (0.009732) with: \"{'knn__n_neighbors': 7}\"\n",
      "mean_test_accuracy: 0.793044 (0.009343) - mean_train_accuracy: 0.855716 (0.009343) with: \"{'knn__n_neighbors': 9}\"\n",
      "mean_test_accuracy: 0.790859 (0.011519) - mean_train_accuracy: 0.846847 (0.011519) with: \"{'knn__n_neighbors': 11}\"\n",
      "mean_test_accuracy: 0.793995 (0.012579) - mean_train_accuracy: 0.842244 (0.012579) with: \"{'knn__n_neighbors': 13}\"\n",
      "mean_test_accuracy: 0.796180 (0.008479) - mean_train_accuracy: 0.837778 (0.008479) with: \"{'knn__n_neighbors': 15}\"\n",
      "mean_test_accuracy: 0.794850 (0.009990) - mean_train_accuracy: 0.834199 (0.009990) with: \"{'knn__n_neighbors': 17}\"\n",
      "mean_test_accuracy: 0.795895 (0.008375) - mean_train_accuracy: 0.831486 (0.008375) with: \"{'knn__n_neighbors': 19}\"\n",
      "mean_test_accuracy: 0.794755 (0.008772) - mean_train_accuracy: 0.828677 (0.008772) with: \"{'knn__n_neighbors': 21}\"\n",
      "mean_test_accuracy: 0.792854 (0.008957) - mean_train_accuracy: 0.824274 (0.008957) with: \"{'knn__n_neighbors': 25}\"\n",
      "mean_test_accuracy: 0.790384 (0.009935) - mean_train_accuracy: 0.819207 (0.009935) with: \"{'knn__n_neighbors': 29}\"\n",
      "mean_test_accuracy: 0.787153 (0.013080) - mean_train_accuracy: 0.813864 (0.013080) with: \"{'knn__n_neighbors': 35}\"\n",
      "mean_test_accuracy: 0.784968 (0.014131) - mean_train_accuracy: 0.808776 (0.014131) with: \"{'knn__n_neighbors': 41}\"\n",
      "mean_test_accuracy: 0.779552 (0.010579) - mean_train_accuracy: 0.802304 (0.010579) with: \"{'knn__n_neighbors': 49}\"\n",
      "mean_test_accuracy: 0.776606 (0.010430) - mean_train_accuracy: 0.796993 (0.010430) with: \"{'knn__n_neighbors': 57}\"\n",
      "mean_test_accuracy: 0.771475 (0.008971) - mean_train_accuracy: 0.787702 (0.008971) with: \"{'knn__n_neighbors': 73}\"\n",
      "mean_test_accuracy: 0.763683 (0.009282) - mean_train_accuracy: 0.778158 (0.009282) with: \"{'knn__n_neighbors': 89}\"\n"
     ]
    }
   ],
   "source": [
    "resultados = pd.read_csv('resultado_pipeline_knn_NSF.csv', sep=';')\n",
    "means_test = resultados['mean_test_accuracy']\n",
    "std_test_acuracy = resultados['std_test_accuracy']\n",
    "means_train = resultados['mean_train_accuracy']\n",
    "std_train_acuracy = resultados['std_test_accuracy']\n",
    "params = resultados['params']\n",
    "\n",
    "for test, stdev_test, train, stdev_train, param in zip(means_test, std_test_acuracy, means_train, std_train_acuracy, params):\n",
    "    print(\"mean_test_accuracy: %f (%f) - mean_train_accuracy: %f (%f) with: %r\" %(test, stdev_test, train, stdev_train, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_test_accuracy: 0.446647 (0.016448) - mean_train_accuracy: 0.690977 (0.016448) with: \"{'knn__n_neighbors': 3}\"\n",
      "mean_test_accuracy: 0.500852 (0.017971) - mean_train_accuracy: 0.679156 (0.017971) with: \"{'knn__n_neighbors': 5}\"\n",
      "mean_test_accuracy: 0.526405 (0.015799) - mean_train_accuracy: 0.674975 (0.015799) with: \"{'knn__n_neighbors': 7}\"\n",
      "mean_test_accuracy: 0.545145 (0.011933) - mean_train_accuracy: 0.670316 (0.011933) with: \"{'knn__n_neighbors': 9}\"\n",
      "mean_test_accuracy: 0.553663 (0.010134) - mean_train_accuracy: 0.665973 (0.010134) with: \"{'knn__n_neighbors': 11}\"\n",
      "mean_test_accuracy: 0.565897 (0.011764) - mean_train_accuracy: 0.661810 (0.011764) with: \"{'knn__n_neighbors': 13}\"\n",
      "mean_test_accuracy: 0.567756 (0.013861) - mean_train_accuracy: 0.658338 (0.013861) with: \"{'knn__n_neighbors': 15}\"\n",
      "mean_test_accuracy: 0.576119 (0.015303) - mean_train_accuracy: 0.658423 (0.015303) with: \"{'knn__n_neighbors': 17}\"\n",
      "mean_test_accuracy: 0.587425 (0.011906) - mean_train_accuracy: 0.658544 (0.011906) with: \"{'knn__n_neighbors': 19}\"\n",
      "mean_test_accuracy: 0.586650 (0.013759) - mean_train_accuracy: 0.657251 (0.013759) with: \"{'knn__n_neighbors': 21}\"\n",
      "mean_test_accuracy: 0.590832 (0.011051) - mean_train_accuracy: 0.653966 (0.011051) with: \"{'knn__n_neighbors': 25}\"\n",
      "mean_test_accuracy: 0.596407 (0.014326) - mean_train_accuracy: 0.649508 (0.014326) with: \"{'knn__n_neighbors': 29}\"\n",
      "mean_test_accuracy: 0.601053 (0.015459) - mean_train_accuracy: 0.648096 (0.015459) with: \"{'knn__n_neighbors': 35}\"\n",
      "mean_test_accuracy: 0.603221 (0.014634) - mean_train_accuracy: 0.646442 (0.014634) with: \"{'knn__n_neighbors': 41}\"\n",
      "mean_test_accuracy: 0.603066 (0.015779) - mean_train_accuracy: 0.641764 (0.015779) with: \"{'knn__n_neighbors': 49}\"\n",
      "mean_test_accuracy: 0.607093 (0.012729) - mean_train_accuracy: 0.637566 (0.012729) with: \"{'knn__n_neighbors': 57}\"\n",
      "mean_test_accuracy: 0.605389 (0.014803) - mean_train_accuracy: 0.630318 (0.014803) with: \"{'knn__n_neighbors': 73}\"\n",
      "mean_test_accuracy: 0.603996 (0.013562) - mean_train_accuracy: 0.624266 (0.013562) with: \"{'knn__n_neighbors': 89}\"\n"
     ]
    }
   ],
   "source": [
    "resultados = pd.read_csv('resultado_pipeline_knn_Opinosis-Parsed.csv', sep=';')\n",
    "means_test = resultados['mean_test_accuracy']\n",
    "std_test_acuracy = resultados['std_test_accuracy']\n",
    "means_train = resultados['mean_train_accuracy']\n",
    "std_train_acuracy = resultados['std_test_accuracy']\n",
    "params = resultados['params']\n",
    "\n",
    "for test, stdev_test, train, stdev_train, param in zip(means_test, std_test_acuracy, means_train, std_train_acuracy, params):\n",
    "    print(\"mean_test_accuracy: %f (%f) - mean_train_accuracy: %f (%f) with: %r\" %(test, stdev_test, train, stdev_train, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_test_accuracy: 0.910347 (0.010811) - mean_train_accuracy: 0.959474 (0.010811) with: \"{'knn__n_neighbors': 3}\"\n",
      "mean_test_accuracy: 0.920381 (0.006616) - mean_train_accuracy: 0.953189 (0.006616) with: \"{'knn__n_neighbors': 5}\"\n",
      "mean_test_accuracy: 0.927938 (0.008928) - mean_train_accuracy: 0.949425 (0.008928) with: \"{'knn__n_neighbors': 7}\"\n",
      "mean_test_accuracy: 0.933542 (0.008045) - mean_train_accuracy: 0.949773 (0.008045) with: \"{'knn__n_neighbors': 9}\"\n",
      "mean_test_accuracy: 0.936409 (0.007826) - mean_train_accuracy: 0.950004 (0.007826) with: \"{'knn__n_neighbors': 11}\"\n",
      "mean_test_accuracy: 0.936409 (0.008232) - mean_train_accuracy: 0.948628 (0.008232) with: \"{'knn__n_neighbors': 13}\"\n",
      "mean_test_accuracy: 0.936930 (0.007765) - mean_train_accuracy: 0.948107 (0.007765) with: \"{'knn__n_neighbors': 15}\"\n",
      "mean_test_accuracy: 0.938103 (0.008129) - mean_train_accuracy: 0.948470 (0.008129) with: \"{'knn__n_neighbors': 17}\"\n",
      "mean_test_accuracy: 0.937451 (0.008381) - mean_train_accuracy: 0.947615 (0.008381) with: \"{'knn__n_neighbors': 19}\"\n",
      "mean_test_accuracy: 0.936539 (0.005552) - mean_train_accuracy: 0.946659 (0.005552) with: \"{'knn__n_neighbors': 21}\"\n",
      "mean_test_accuracy: 0.938233 (0.006497) - mean_train_accuracy: 0.946124 (0.006497) with: \"{'knn__n_neighbors': 25}\"\n",
      "mean_test_accuracy: 0.936930 (0.007116) - mean_train_accuracy: 0.946066 (0.007116) with: \"{'knn__n_neighbors': 29}\"\n",
      "mean_test_accuracy: 0.939145 (0.006731) - mean_train_accuracy: 0.945342 (0.006731) with: \"{'knn__n_neighbors': 35}\"\n",
      "mean_test_accuracy: 0.935627 (0.005816) - mean_train_accuracy: 0.943185 (0.005816) with: \"{'knn__n_neighbors': 41}\"\n",
      "mean_test_accuracy: 0.936148 (0.007532) - mean_train_accuracy: 0.940158 (0.007532) with: \"{'knn__n_neighbors': 49}\"\n",
      "mean_test_accuracy: 0.933412 (0.007574) - mean_train_accuracy: 0.938957 (0.007574) with: \"{'knn__n_neighbors': 57}\"\n",
      "mean_test_accuracy: 0.929372 (0.011799) - mean_train_accuracy: 0.934715 (0.011799) with: \"{'knn__n_neighbors': 73}\"\n",
      "mean_test_accuracy: 0.927417 (0.010699) - mean_train_accuracy: 0.931167 (0.010699) with: \"{'knn__n_neighbors': 89}\"\n"
     ]
    }
   ],
   "source": [
    "resultados = pd.read_csv('resultado_pipeline_knn_re8.csv', sep=';')\n",
    "means_test = resultados['mean_test_accuracy']\n",
    "std_test_acuracy = resultados['std_test_accuracy']\n",
    "means_train = resultados['mean_train_accuracy']\n",
    "std_train_acuracy = resultados['std_test_accuracy']\n",
    "params = resultados['params']\n",
    "\n",
    "for test, stdev_test, train, stdev_train, param in zip(means_test, std_test_acuracy, means_train, std_train_acuracy, params):\n",
    "    print(\"mean_test_accuracy: %f (%f) - mean_train_accuracy: %f (%f) with: %r\" %(test, stdev_test, train, stdev_train, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_test_accuracy: 0.636500 (0.025204) - mean_train_accuracy: 0.781611 (0.025204) with: \"{'knn__n_neighbors': 3}\"\n",
      "mean_test_accuracy: 0.595000 (0.015000) - mean_train_accuracy: 0.700222 (0.015000) with: \"{'knn__n_neighbors': 5}\"\n",
      "mean_test_accuracy: 0.575500 (0.018364) - mean_train_accuracy: 0.639444 (0.018364) with: \"{'knn__n_neighbors': 7}\"\n",
      "mean_test_accuracy: 0.562000 (0.016912) - mean_train_accuracy: 0.606333 (0.016912) with: \"{'knn__n_neighbors': 9}\"\n",
      "mean_test_accuracy: 0.550500 (0.017671) - mean_train_accuracy: 0.585333 (0.017671) with: \"{'knn__n_neighbors': 11}\"\n",
      "mean_test_accuracy: 0.544500 (0.016039) - mean_train_accuracy: 0.572667 (0.016039) with: \"{'knn__n_neighbors': 13}\"\n",
      "mean_test_accuracy: 0.540000 (0.018708) - mean_train_accuracy: 0.559833 (0.018708) with: \"{'knn__n_neighbors': 15}\"\n",
      "mean_test_accuracy: 0.528000 (0.014526) - mean_train_accuracy: 0.551167 (0.014526) with: \"{'knn__n_neighbors': 17}\"\n",
      "mean_test_accuracy: 0.528000 (0.019647) - mean_train_accuracy: 0.543222 (0.019647) with: \"{'knn__n_neighbors': 19}\"\n",
      "mean_test_accuracy: 0.526000 (0.016248) - mean_train_accuracy: 0.537944 (0.016248) with: \"{'knn__n_neighbors': 21}\"\n",
      "mean_test_accuracy: 0.529500 (0.018768) - mean_train_accuracy: 0.536833 (0.018768) with: \"{'knn__n_neighbors': 25}\"\n",
      "mean_test_accuracy: 0.526000 (0.019468) - mean_train_accuracy: 0.536778 (0.019468) with: \"{'knn__n_neighbors': 29}\"\n",
      "mean_test_accuracy: 0.522000 (0.023580) - mean_train_accuracy: 0.533722 (0.023580) with: \"{'knn__n_neighbors': 35}\"\n",
      "mean_test_accuracy: 0.524000 (0.020224) - mean_train_accuracy: 0.536833 (0.020224) with: \"{'knn__n_neighbors': 41}\"\n",
      "mean_test_accuracy: 0.532000 (0.019900) - mean_train_accuracy: 0.542722 (0.019900) with: \"{'knn__n_neighbors': 49}\"\n",
      "mean_test_accuracy: 0.540500 (0.019164) - mean_train_accuracy: 0.549056 (0.019164) with: \"{'knn__n_neighbors': 57}\"\n",
      "mean_test_accuracy: 0.547500 (0.022277) - mean_train_accuracy: 0.560667 (0.022277) with: \"{'knn__n_neighbors': 73}\"\n",
      "mean_test_accuracy: 0.549500 (0.024541) - mean_train_accuracy: 0.560778 (0.024541) with: \"{'knn__n_neighbors': 89}\"\n"
     ]
    }
   ],
   "source": [
    "resultados = pd.read_csv('resultado_pipeline_knn_review_polarity.csv', sep=';')\n",
    "means_test = resultados['mean_test_accuracy']\n",
    "std_test_acuracy = resultados['std_test_accuracy']\n",
    "means_train = resultados['mean_train_accuracy']\n",
    "std_train_acuracy = resultados['std_test_accuracy']\n",
    "params = resultados['params']\n",
    "\n",
    "for test, stdev_test, train, stdev_train, param in zip(means_test, std_test_acuracy, means_train, std_train_acuracy, params):\n",
    "    print(\"mean_test_accuracy: %f (%f) - mean_train_accuracy: %f (%f) with: %r\" %(test, stdev_test, train, stdev_train, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_test_accuracy: 0.905136 (0.012702) - mean_train_accuracy: 0.950001 (0.012702) with: \"{'knn__n_neighbors': 3}\"\n",
      "mean_test_accuracy: 0.915458 (0.009299) - mean_train_accuracy: 0.944403 (0.009299) with: \"{'knn__n_neighbors': 5}\"\n",
      "mean_test_accuracy: 0.917179 (0.011844) - mean_train_accuracy: 0.942601 (0.011844) with: \"{'knn__n_neighbors': 7}\"\n",
      "mean_test_accuracy: 0.923568 (0.011164) - mean_train_accuracy: 0.939133 (0.011164) with: \"{'knn__n_neighbors': 9}\"\n",
      "mean_test_accuracy: 0.924797 (0.009358) - mean_train_accuracy: 0.938587 (0.009358) with: \"{'knn__n_neighbors': 11}\"\n",
      "mean_test_accuracy: 0.925535 (0.011117) - mean_train_accuracy: 0.940717 (0.011117) with: \"{'knn__n_neighbors': 13}\"\n",
      "mean_test_accuracy: 0.925289 (0.010047) - mean_train_accuracy: 0.940745 (0.010047) with: \"{'knn__n_neighbors': 15}\"\n",
      "mean_test_accuracy: 0.925535 (0.011680) - mean_train_accuracy: 0.940881 (0.011680) with: \"{'knn__n_neighbors': 17}\"\n",
      "mean_test_accuracy: 0.924306 (0.010590) - mean_train_accuracy: 0.939325 (0.010590) with: \"{'knn__n_neighbors': 19}\"\n",
      "mean_test_accuracy: 0.927501 (0.011260) - mean_train_accuracy: 0.937304 (0.011260) with: \"{'knn__n_neighbors': 21}\"\n",
      "mean_test_accuracy: 0.926518 (0.011908) - mean_train_accuracy: 0.936621 (0.011908) with: \"{'knn__n_neighbors': 25}\"\n",
      "mean_test_accuracy: 0.926272 (0.008650) - mean_train_accuracy: 0.935147 (0.008650) with: \"{'knn__n_neighbors': 29}\"\n",
      "mean_test_accuracy: 0.926763 (0.007281) - mean_train_accuracy: 0.931597 (0.007281) with: \"{'knn__n_neighbors': 35}\"\n",
      "mean_test_accuracy: 0.925043 (0.008889) - mean_train_accuracy: 0.929330 (0.008889) with: \"{'knn__n_neighbors': 41}\"\n",
      "mean_test_accuracy: 0.923814 (0.010552) - mean_train_accuracy: 0.926954 (0.010552) with: \"{'knn__n_neighbors': 49}\"\n",
      "mean_test_accuracy: 0.923568 (0.009644) - mean_train_accuracy: 0.925480 (0.009644) with: \"{'knn__n_neighbors': 57}\"\n",
      "mean_test_accuracy: 0.924060 (0.012599) - mean_train_accuracy: 0.926818 (0.012599) with: \"{'knn__n_neighbors': 73}\"\n",
      "mean_test_accuracy: 0.923323 (0.013840) - mean_train_accuracy: 0.926709 (0.013840) with: \"{'knn__n_neighbors': 89}\"\n"
     ]
    }
   ],
   "source": [
    "resultados = pd.read_csv('resultado_pipeline_knn_Reviews.csv', sep=';')\n",
    "means_test = resultados['mean_test_accuracy']\n",
    "std_test_acuracy = resultados['std_test_accuracy']\n",
    "means_train = resultados['mean_train_accuracy']\n",
    "std_train_acuracy = resultados['std_test_accuracy']\n",
    "params = resultados['params']\n",
    "\n",
    "for test, stdev_test, train, stdev_train, param in zip(means_test, std_test_acuracy, means_train, std_train_acuracy, params):\n",
    "    print(\"mean_test_accuracy: %f (%f) - mean_train_accuracy: %f (%f) with: %r\" %(test, stdev_test, train, stdev_train, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_test_accuracy: 0.856287 (0.036762) - mean_train_accuracy: 0.937101 (0.036762) with: \"{'knn__n_neighbors': 3}\"\n",
      "mean_test_accuracy: 0.880240 (0.047357) - mean_train_accuracy: 0.935775 (0.047357) with: \"{'knn__n_neighbors': 5}\"\n",
      "mean_test_accuracy: 0.892216 (0.054467) - mean_train_accuracy: 0.924481 (0.054467) with: \"{'knn__n_neighbors': 7}\"\n",
      "mean_test_accuracy: 0.889222 (0.050049) - mean_train_accuracy: 0.923134 (0.050049) with: \"{'knn__n_neighbors': 9}\"\n",
      "mean_test_accuracy: 0.886228 (0.059395) - mean_train_accuracy: 0.917815 (0.059395) with: \"{'knn__n_neighbors': 11}\"\n",
      "mean_test_accuracy: 0.883234 (0.060634) - mean_train_accuracy: 0.910844 (0.060634) with: \"{'knn__n_neighbors': 13}\"\n",
      "mean_test_accuracy: 0.877246 (0.056879) - mean_train_accuracy: 0.899532 (0.056879) with: \"{'knn__n_neighbors': 15}\"\n",
      "mean_test_accuracy: 0.877246 (0.056420) - mean_train_accuracy: 0.895212 (0.056420) with: \"{'knn__n_neighbors': 17}\"\n",
      "mean_test_accuracy: 0.865269 (0.060249) - mean_train_accuracy: 0.891547 (0.060249) with: \"{'knn__n_neighbors': 19}\"\n",
      "mean_test_accuracy: 0.871257 (0.066054) - mean_train_accuracy: 0.885894 (0.066054) with: \"{'knn__n_neighbors': 21}\"\n",
      "mean_test_accuracy: 0.859281 (0.061662) - mean_train_accuracy: 0.878918 (0.061662) with: \"{'knn__n_neighbors': 25}\"\n",
      "mean_test_accuracy: 0.850299 (0.073421) - mean_train_accuracy: 0.868605 (0.073421) with: \"{'knn__n_neighbors': 29}\"\n",
      "mean_test_accuracy: 0.844311 (0.067762) - mean_train_accuracy: 0.857624 (0.067762) with: \"{'knn__n_neighbors': 35}\"\n",
      "mean_test_accuracy: 0.829341 (0.058998) - mean_train_accuracy: 0.843304 (0.058998) with: \"{'knn__n_neighbors': 41}\"\n",
      "mean_test_accuracy: 0.835329 (0.057602) - mean_train_accuracy: 0.830336 (0.057602) with: \"{'knn__n_neighbors': 49}\"\n",
      "mean_test_accuracy: 0.823353 (0.063019) - mean_train_accuracy: 0.817702 (0.063019) with: \"{'knn__n_neighbors': 57}\"\n",
      "mean_test_accuracy: 0.811377 (0.045943) - mean_train_accuracy: 0.809373 (0.045943) with: \"{'knn__n_neighbors': 73}\"\n",
      "mean_test_accuracy: 0.811377 (0.035826) - mean_train_accuracy: 0.797419 (0.035826) with: \"{'knn__n_neighbors': 89}\"\n"
     ]
    }
   ],
   "source": [
    "resultados = pd.read_csv('resultado_pipeline_knn_Syskillwebert-Parsed.csv', sep=';')\n",
    "means_test = resultados['mean_test_accuracy']\n",
    "std_test_acuracy = resultados['std_test_accuracy']\n",
    "means_train = resultados['mean_train_accuracy']\n",
    "std_train_acuracy = resultados['std_test_accuracy']\n",
    "params = resultados['params']\n",
    "\n",
    "for test, stdev_test, train, stdev_train, param in zip(means_test, std_test_acuracy, means_train, std_train_acuracy, params):\n",
    "    print(\"mean_test_accuracy: %f (%f) - mean_train_accuracy: %f (%f) with: %r\" %(test, stdev_test, train, stdev_train, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
