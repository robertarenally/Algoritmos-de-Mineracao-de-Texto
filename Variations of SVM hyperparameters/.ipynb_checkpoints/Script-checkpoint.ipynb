{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = pd.read_csv('resultado_pipeline_svm_20ng.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>mean_test_f1_macro</th>\n",
       "      <th>mean_test_f1_micro</th>\n",
       "      <th>mean_train_accuracy</th>\n",
       "      <th>mean_train_f1_macro</th>\n",
       "      <th>mean_train_f1_micro</th>\n",
       "      <th>param_svc__C</th>\n",
       "      <th>...</th>\n",
       "      <th>split9_train_f1_macro</th>\n",
       "      <th>split9_train_f1_micro</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>std_test_f1_macro</th>\n",
       "      <th>std_test_f1_micro</th>\n",
       "      <th>std_train_accuracy</th>\n",
       "      <th>std_train_f1_macro</th>\n",
       "      <th>std_train_f1_micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>128.451678</td>\n",
       "      <td>28.995920</td>\n",
       "      <td>0.915415</td>\n",
       "      <td>0.916114</td>\n",
       "      <td>0.915415</td>\n",
       "      <td>0.999725</td>\n",
       "      <td>0.999736</td>\n",
       "      <td>0.999725</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999718</td>\n",
       "      <td>0.999706</td>\n",
       "      <td>4.018253</td>\n",
       "      <td>1.114320</td>\n",
       "      <td>0.005862</td>\n",
       "      <td>0.005882</td>\n",
       "      <td>0.005862</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>222.819986</td>\n",
       "      <td>37.712147</td>\n",
       "      <td>0.054976</td>\n",
       "      <td>0.007350</td>\n",
       "      <td>0.054976</td>\n",
       "      <td>0.055161</td>\n",
       "      <td>0.007306</td>\n",
       "      <td>0.055161</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027727</td>\n",
       "      <td>0.074281</td>\n",
       "      <td>5.026032</td>\n",
       "      <td>0.790542</td>\n",
       "      <td>0.005994</td>\n",
       "      <td>0.006984</td>\n",
       "      <td>0.005994</td>\n",
       "      <td>0.006373</td>\n",
       "      <td>0.006807</td>\n",
       "      <td>0.006373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>235.597523</td>\n",
       "      <td>36.439390</td>\n",
       "      <td>0.057363</td>\n",
       "      <td>0.007123</td>\n",
       "      <td>0.057363</td>\n",
       "      <td>0.057379</td>\n",
       "      <td>0.007102</td>\n",
       "      <td>0.057379</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025691</td>\n",
       "      <td>0.096458</td>\n",
       "      <td>4.906385</td>\n",
       "      <td>0.847674</td>\n",
       "      <td>0.013181</td>\n",
       "      <td>0.006298</td>\n",
       "      <td>0.013181</td>\n",
       "      <td>0.013026</td>\n",
       "      <td>0.006196</td>\n",
       "      <td>0.013026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>125.720718</td>\n",
       "      <td>28.498946</td>\n",
       "      <td>0.915415</td>\n",
       "      <td>0.916114</td>\n",
       "      <td>0.915415</td>\n",
       "      <td>0.999725</td>\n",
       "      <td>0.999736</td>\n",
       "      <td>0.999725</td>\n",
       "      <td>101</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999718</td>\n",
       "      <td>0.999706</td>\n",
       "      <td>2.299223</td>\n",
       "      <td>0.679049</td>\n",
       "      <td>0.005862</td>\n",
       "      <td>0.005882</td>\n",
       "      <td>0.005862</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>222.686982</td>\n",
       "      <td>37.949237</td>\n",
       "      <td>0.054976</td>\n",
       "      <td>0.007350</td>\n",
       "      <td>0.054976</td>\n",
       "      <td>0.055161</td>\n",
       "      <td>0.007306</td>\n",
       "      <td>0.055161</td>\n",
       "      <td>101</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027727</td>\n",
       "      <td>0.074281</td>\n",
       "      <td>3.697804</td>\n",
       "      <td>1.166112</td>\n",
       "      <td>0.005994</td>\n",
       "      <td>0.006984</td>\n",
       "      <td>0.005994</td>\n",
       "      <td>0.006373</td>\n",
       "      <td>0.006807</td>\n",
       "      <td>0.006373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>236.546091</td>\n",
       "      <td>36.231245</td>\n",
       "      <td>0.057363</td>\n",
       "      <td>0.007123</td>\n",
       "      <td>0.057363</td>\n",
       "      <td>0.057379</td>\n",
       "      <td>0.007102</td>\n",
       "      <td>0.057379</td>\n",
       "      <td>101</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025691</td>\n",
       "      <td>0.096458</td>\n",
       "      <td>4.739829</td>\n",
       "      <td>0.914279</td>\n",
       "      <td>0.013181</td>\n",
       "      <td>0.006298</td>\n",
       "      <td>0.013181</td>\n",
       "      <td>0.013026</td>\n",
       "      <td>0.006196</td>\n",
       "      <td>0.013026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>126.170155</td>\n",
       "      <td>28.700076</td>\n",
       "      <td>0.915415</td>\n",
       "      <td>0.916114</td>\n",
       "      <td>0.915415</td>\n",
       "      <td>0.999725</td>\n",
       "      <td>0.999736</td>\n",
       "      <td>0.999725</td>\n",
       "      <td>102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999718</td>\n",
       "      <td>0.999706</td>\n",
       "      <td>3.301683</td>\n",
       "      <td>0.704660</td>\n",
       "      <td>0.005862</td>\n",
       "      <td>0.005882</td>\n",
       "      <td>0.005862</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>222.042522</td>\n",
       "      <td>37.701610</td>\n",
       "      <td>0.054976</td>\n",
       "      <td>0.007350</td>\n",
       "      <td>0.054976</td>\n",
       "      <td>0.055161</td>\n",
       "      <td>0.007306</td>\n",
       "      <td>0.055161</td>\n",
       "      <td>102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027727</td>\n",
       "      <td>0.074281</td>\n",
       "      <td>4.529399</td>\n",
       "      <td>1.064842</td>\n",
       "      <td>0.005994</td>\n",
       "      <td>0.006984</td>\n",
       "      <td>0.005994</td>\n",
       "      <td>0.006373</td>\n",
       "      <td>0.006807</td>\n",
       "      <td>0.006373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>236.659101</td>\n",
       "      <td>36.414651</td>\n",
       "      <td>0.057363</td>\n",
       "      <td>0.007123</td>\n",
       "      <td>0.057363</td>\n",
       "      <td>0.057379</td>\n",
       "      <td>0.007102</td>\n",
       "      <td>0.057379</td>\n",
       "      <td>102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025691</td>\n",
       "      <td>0.096458</td>\n",
       "      <td>5.811087</td>\n",
       "      <td>0.839690</td>\n",
       "      <td>0.013181</td>\n",
       "      <td>0.006298</td>\n",
       "      <td>0.013181</td>\n",
       "      <td>0.013026</td>\n",
       "      <td>0.006196</td>\n",
       "      <td>0.013026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>124.991264</td>\n",
       "      <td>28.484971</td>\n",
       "      <td>0.915415</td>\n",
       "      <td>0.916111</td>\n",
       "      <td>0.915415</td>\n",
       "      <td>0.999725</td>\n",
       "      <td>0.999736</td>\n",
       "      <td>0.999725</td>\n",
       "      <td>103</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999718</td>\n",
       "      <td>0.999706</td>\n",
       "      <td>2.214638</td>\n",
       "      <td>0.672640</td>\n",
       "      <td>0.005862</td>\n",
       "      <td>0.005883</td>\n",
       "      <td>0.005862</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>221.981963</td>\n",
       "      <td>37.722898</td>\n",
       "      <td>0.054976</td>\n",
       "      <td>0.007350</td>\n",
       "      <td>0.054976</td>\n",
       "      <td>0.055161</td>\n",
       "      <td>0.007306</td>\n",
       "      <td>0.055161</td>\n",
       "      <td>103</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027727</td>\n",
       "      <td>0.074281</td>\n",
       "      <td>4.201888</td>\n",
       "      <td>0.999102</td>\n",
       "      <td>0.005994</td>\n",
       "      <td>0.006984</td>\n",
       "      <td>0.005994</td>\n",
       "      <td>0.006373</td>\n",
       "      <td>0.006807</td>\n",
       "      <td>0.006373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>236.705432</td>\n",
       "      <td>36.398092</td>\n",
       "      <td>0.057363</td>\n",
       "      <td>0.007123</td>\n",
       "      <td>0.057363</td>\n",
       "      <td>0.057379</td>\n",
       "      <td>0.007102</td>\n",
       "      <td>0.057379</td>\n",
       "      <td>103</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025691</td>\n",
       "      <td>0.096458</td>\n",
       "      <td>5.521290</td>\n",
       "      <td>0.829798</td>\n",
       "      <td>0.013181</td>\n",
       "      <td>0.006298</td>\n",
       "      <td>0.013181</td>\n",
       "      <td>0.013026</td>\n",
       "      <td>0.006196</td>\n",
       "      <td>0.013026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>125.369927</td>\n",
       "      <td>28.517483</td>\n",
       "      <td>0.915415</td>\n",
       "      <td>0.916111</td>\n",
       "      <td>0.915415</td>\n",
       "      <td>0.999725</td>\n",
       "      <td>0.999736</td>\n",
       "      <td>0.999725</td>\n",
       "      <td>104</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999718</td>\n",
       "      <td>0.999706</td>\n",
       "      <td>2.743669</td>\n",
       "      <td>0.724056</td>\n",
       "      <td>0.005862</td>\n",
       "      <td>0.005883</td>\n",
       "      <td>0.005862</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>222.076638</td>\n",
       "      <td>37.731235</td>\n",
       "      <td>0.054976</td>\n",
       "      <td>0.007350</td>\n",
       "      <td>0.054976</td>\n",
       "      <td>0.055161</td>\n",
       "      <td>0.007306</td>\n",
       "      <td>0.055161</td>\n",
       "      <td>104</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027727</td>\n",
       "      <td>0.074281</td>\n",
       "      <td>4.873412</td>\n",
       "      <td>0.948348</td>\n",
       "      <td>0.005994</td>\n",
       "      <td>0.006984</td>\n",
       "      <td>0.005994</td>\n",
       "      <td>0.006373</td>\n",
       "      <td>0.006807</td>\n",
       "      <td>0.006373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>236.728916</td>\n",
       "      <td>36.435388</td>\n",
       "      <td>0.057363</td>\n",
       "      <td>0.007123</td>\n",
       "      <td>0.057363</td>\n",
       "      <td>0.057379</td>\n",
       "      <td>0.007102</td>\n",
       "      <td>0.057379</td>\n",
       "      <td>104</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025691</td>\n",
       "      <td>0.096458</td>\n",
       "      <td>5.847553</td>\n",
       "      <td>0.821205</td>\n",
       "      <td>0.013181</td>\n",
       "      <td>0.006298</td>\n",
       "      <td>0.013181</td>\n",
       "      <td>0.013026</td>\n",
       "      <td>0.006196</td>\n",
       "      <td>0.013026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>124.745339</td>\n",
       "      <td>28.496720</td>\n",
       "      <td>0.915326</td>\n",
       "      <td>0.916028</td>\n",
       "      <td>0.915326</td>\n",
       "      <td>0.999725</td>\n",
       "      <td>0.999736</td>\n",
       "      <td>0.999725</td>\n",
       "      <td>105</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999718</td>\n",
       "      <td>0.999706</td>\n",
       "      <td>2.278010</td>\n",
       "      <td>0.675117</td>\n",
       "      <td>0.005841</td>\n",
       "      <td>0.005847</td>\n",
       "      <td>0.005841</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>221.866726</td>\n",
       "      <td>37.704507</td>\n",
       "      <td>0.054976</td>\n",
       "      <td>0.007350</td>\n",
       "      <td>0.054976</td>\n",
       "      <td>0.055161</td>\n",
       "      <td>0.007306</td>\n",
       "      <td>0.055161</td>\n",
       "      <td>105</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027727</td>\n",
       "      <td>0.074281</td>\n",
       "      <td>4.592138</td>\n",
       "      <td>0.989648</td>\n",
       "      <td>0.005994</td>\n",
       "      <td>0.006984</td>\n",
       "      <td>0.005994</td>\n",
       "      <td>0.006373</td>\n",
       "      <td>0.006807</td>\n",
       "      <td>0.006373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>236.675163</td>\n",
       "      <td>36.390053</td>\n",
       "      <td>0.057363</td>\n",
       "      <td>0.007123</td>\n",
       "      <td>0.057363</td>\n",
       "      <td>0.057379</td>\n",
       "      <td>0.007102</td>\n",
       "      <td>0.057379</td>\n",
       "      <td>105</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025691</td>\n",
       "      <td>0.096458</td>\n",
       "      <td>5.728592</td>\n",
       "      <td>0.853100</td>\n",
       "      <td>0.013181</td>\n",
       "      <td>0.006298</td>\n",
       "      <td>0.013181</td>\n",
       "      <td>0.013026</td>\n",
       "      <td>0.006196</td>\n",
       "      <td>0.013026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  mean_fit_time  mean_score_time  mean_test_accuracy  \\\n",
       "0            0     128.451678        28.995920            0.915415   \n",
       "1            1     222.819986        37.712147            0.054976   \n",
       "2            2     235.597523        36.439390            0.057363   \n",
       "3            3     125.720718        28.498946            0.915415   \n",
       "4            4     222.686982        37.949237            0.054976   \n",
       "5            5     236.546091        36.231245            0.057363   \n",
       "6            6     126.170155        28.700076            0.915415   \n",
       "7            7     222.042522        37.701610            0.054976   \n",
       "8            8     236.659101        36.414651            0.057363   \n",
       "9            9     124.991264        28.484971            0.915415   \n",
       "10          10     221.981963        37.722898            0.054976   \n",
       "11          11     236.705432        36.398092            0.057363   \n",
       "12          12     125.369927        28.517483            0.915415   \n",
       "13          13     222.076638        37.731235            0.054976   \n",
       "14          14     236.728916        36.435388            0.057363   \n",
       "15          15     124.745339        28.496720            0.915326   \n",
       "16          16     221.866726        37.704507            0.054976   \n",
       "17          17     236.675163        36.390053            0.057363   \n",
       "\n",
       "    mean_test_f1_macro  mean_test_f1_micro  mean_train_accuracy  \\\n",
       "0             0.916114            0.915415             0.999725   \n",
       "1             0.007350            0.054976             0.055161   \n",
       "2             0.007123            0.057363             0.057379   \n",
       "3             0.916114            0.915415             0.999725   \n",
       "4             0.007350            0.054976             0.055161   \n",
       "5             0.007123            0.057363             0.057379   \n",
       "6             0.916114            0.915415             0.999725   \n",
       "7             0.007350            0.054976             0.055161   \n",
       "8             0.007123            0.057363             0.057379   \n",
       "9             0.916111            0.915415             0.999725   \n",
       "10            0.007350            0.054976             0.055161   \n",
       "11            0.007123            0.057363             0.057379   \n",
       "12            0.916111            0.915415             0.999725   \n",
       "13            0.007350            0.054976             0.055161   \n",
       "14            0.007123            0.057363             0.057379   \n",
       "15            0.916028            0.915326             0.999725   \n",
       "16            0.007350            0.054976             0.055161   \n",
       "17            0.007123            0.057363             0.057379   \n",
       "\n",
       "    mean_train_f1_macro  mean_train_f1_micro  param_svc__C  \\\n",
       "0              0.999736             0.999725           100   \n",
       "1              0.007306             0.055161           100   \n",
       "2              0.007102             0.057379           100   \n",
       "3              0.999736             0.999725           101   \n",
       "4              0.007306             0.055161           101   \n",
       "5              0.007102             0.057379           101   \n",
       "6              0.999736             0.999725           102   \n",
       "7              0.007306             0.055161           102   \n",
       "8              0.007102             0.057379           102   \n",
       "9              0.999736             0.999725           103   \n",
       "10             0.007306             0.055161           103   \n",
       "11             0.007102             0.057379           103   \n",
       "12             0.999736             0.999725           104   \n",
       "13             0.007306             0.055161           104   \n",
       "14             0.007102             0.057379           104   \n",
       "15             0.999736             0.999725           105   \n",
       "16             0.007306             0.055161           105   \n",
       "17             0.007102             0.057379           105   \n",
       "\n",
       "           ...         split9_train_f1_macro split9_train_f1_micro  \\\n",
       "0          ...                      0.999718              0.999706   \n",
       "1          ...                      0.027727              0.074281   \n",
       "2          ...                      0.025691              0.096458   \n",
       "3          ...                      0.999718              0.999706   \n",
       "4          ...                      0.027727              0.074281   \n",
       "5          ...                      0.025691              0.096458   \n",
       "6          ...                      0.999718              0.999706   \n",
       "7          ...                      0.027727              0.074281   \n",
       "8          ...                      0.025691              0.096458   \n",
       "9          ...                      0.999718              0.999706   \n",
       "10         ...                      0.027727              0.074281   \n",
       "11         ...                      0.025691              0.096458   \n",
       "12         ...                      0.999718              0.999706   \n",
       "13         ...                      0.027727              0.074281   \n",
       "14         ...                      0.025691              0.096458   \n",
       "15         ...                      0.999718              0.999706   \n",
       "16         ...                      0.027727              0.074281   \n",
       "17         ...                      0.025691              0.096458   \n",
       "\n",
       "    std_fit_time  std_score_time  std_test_accuracy  std_test_f1_macro  \\\n",
       "0       4.018253        1.114320           0.005862           0.005882   \n",
       "1       5.026032        0.790542           0.005994           0.006984   \n",
       "2       4.906385        0.847674           0.013181           0.006298   \n",
       "3       2.299223        0.679049           0.005862           0.005882   \n",
       "4       3.697804        1.166112           0.005994           0.006984   \n",
       "5       4.739829        0.914279           0.013181           0.006298   \n",
       "6       3.301683        0.704660           0.005862           0.005882   \n",
       "7       4.529399        1.064842           0.005994           0.006984   \n",
       "8       5.811087        0.839690           0.013181           0.006298   \n",
       "9       2.214638        0.672640           0.005862           0.005883   \n",
       "10      4.201888        0.999102           0.005994           0.006984   \n",
       "11      5.521290        0.829798           0.013181           0.006298   \n",
       "12      2.743669        0.724056           0.005862           0.005883   \n",
       "13      4.873412        0.948348           0.005994           0.006984   \n",
       "14      5.847553        0.821205           0.013181           0.006298   \n",
       "15      2.278010        0.675117           0.005841           0.005847   \n",
       "16      4.592138        0.989648           0.005994           0.006984   \n",
       "17      5.728592        0.853100           0.013181           0.006298   \n",
       "\n",
       "    std_test_f1_micro  std_train_accuracy  std_train_f1_macro  \\\n",
       "0            0.005862            0.000039            0.000038   \n",
       "1            0.005994            0.006373            0.006807   \n",
       "2            0.013181            0.013026            0.006196   \n",
       "3            0.005862            0.000039            0.000038   \n",
       "4            0.005994            0.006373            0.006807   \n",
       "5            0.013181            0.013026            0.006196   \n",
       "6            0.005862            0.000039            0.000038   \n",
       "7            0.005994            0.006373            0.006807   \n",
       "8            0.013181            0.013026            0.006196   \n",
       "9            0.005862            0.000039            0.000038   \n",
       "10           0.005994            0.006373            0.006807   \n",
       "11           0.013181            0.013026            0.006196   \n",
       "12           0.005862            0.000039            0.000038   \n",
       "13           0.005994            0.006373            0.006807   \n",
       "14           0.013181            0.013026            0.006196   \n",
       "15           0.005841            0.000039            0.000038   \n",
       "16           0.005994            0.006373            0.006807   \n",
       "17           0.013181            0.013026            0.006196   \n",
       "\n",
       "    std_train_f1_micro  \n",
       "0             0.000039  \n",
       "1             0.006373  \n",
       "2             0.013026  \n",
       "3             0.000039  \n",
       "4             0.006373  \n",
       "5             0.013026  \n",
       "6             0.000039  \n",
       "7             0.006373  \n",
       "8             0.013026  \n",
       "9             0.000039  \n",
       "10            0.006373  \n",
       "11            0.013026  \n",
       "12            0.000039  \n",
       "13            0.006373  \n",
       "14            0.013026  \n",
       "15            0.000039  \n",
       "16            0.006373  \n",
       "17            0.013026  \n",
       "\n",
       "[18 rows x 83 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_test_accuracy: 0.915415 (0.005862) - mean_train_accuracy: 0.999725 (0.005862) with: \"{'svc__C': 100; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.054976 (0.005994) - mean_train_accuracy: 0.055161 (0.005994) with: \"{'svc__C': 100; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.057363 (0.013181) - mean_train_accuracy: 0.057379 (0.013181) with: \"{'svc__C': 100; 'svc__kernel': 'rbf'}\"\n",
      "mean_test_accuracy: 0.915415 (0.005862) - mean_train_accuracy: 0.999725 (0.005862) with: \"{'svc__C': 101; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.054976 (0.005994) - mean_train_accuracy: 0.055161 (0.005994) with: \"{'svc__C': 101; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.057363 (0.013181) - mean_train_accuracy: 0.057379 (0.013181) with: \"{'svc__C': 101; 'svc__kernel': 'rbf'}\"\n",
      "mean_test_accuracy: 0.915415 (0.005862) - mean_train_accuracy: 0.999725 (0.005862) with: \"{'svc__C': 102; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.054976 (0.005994) - mean_train_accuracy: 0.055161 (0.005994) with: \"{'svc__C': 102; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.057363 (0.013181) - mean_train_accuracy: 0.057379 (0.013181) with: \"{'svc__C': 102; 'svc__kernel': 'rbf'}\"\n",
      "mean_test_accuracy: 0.915415 (0.005862) - mean_train_accuracy: 0.999725 (0.005862) with: \"{'svc__C': 103; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.054976 (0.005994) - mean_train_accuracy: 0.055161 (0.005994) with: \"{'svc__C': 103; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.057363 (0.013181) - mean_train_accuracy: 0.057379 (0.013181) with: \"{'svc__C': 103; 'svc__kernel': 'rbf'}\"\n",
      "mean_test_accuracy: 0.915415 (0.005862) - mean_train_accuracy: 0.999725 (0.005862) with: \"{'svc__C': 104; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.054976 (0.005994) - mean_train_accuracy: 0.055161 (0.005994) with: \"{'svc__C': 104; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.057363 (0.013181) - mean_train_accuracy: 0.057379 (0.013181) with: \"{'svc__C': 104; 'svc__kernel': 'rbf'}\"\n",
      "mean_test_accuracy: 0.915326 (0.005841) - mean_train_accuracy: 0.999725 (0.005841) with: \"{'svc__C': 105; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.054976 (0.005994) - mean_train_accuracy: 0.055161 (0.005994) with: \"{'svc__C': 105; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.057363 (0.013181) - mean_train_accuracy: 0.057379 (0.013181) with: \"{'svc__C': 105; 'svc__kernel': 'rbf'}\"\n"
     ]
    }
   ],
   "source": [
    "means_test = resultados['mean_test_accuracy']\n",
    "std_test_acuracy = resultados['std_test_accuracy']\n",
    "means_train = resultados['mean_train_accuracy']\n",
    "std_train_acuracy = resultados['std_test_accuracy']\n",
    "params = resultados['params']\n",
    "\n",
    "for test, stdev_test, train, stdev_train, param in zip(means_test, std_test_acuracy, means_train, std_train_acuracy, params):\n",
    "    print(\"mean_test_accuracy: %f (%f) - mean_train_accuracy: %f (%f) with: %r\" %(test, stdev_test, train, stdev_train, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = pd.read_csv('resultado_pipeline_svm_classic3.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_test_accuracy: 0.974771 (0.004152) - mean_train_accuracy: 1.000000 (0.004152) with: \"{'svc__C': 100; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.451586 (0.000293) - mean_train_accuracy: 0.451586 (0.000293) with: \"{'svc__C': 100; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.525159 (0.007450) - mean_train_accuracy: 0.525253 (0.007450) with: \"{'svc__C': 100; 'svc__kernel': 'rbf'}\"\n",
      "mean_test_accuracy: 0.974771 (0.004152) - mean_train_accuracy: 1.000000 (0.004152) with: \"{'svc__C': 101; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.451586 (0.000293) - mean_train_accuracy: 0.451586 (0.000293) with: \"{'svc__C': 101; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.527414 (0.007492) - mean_train_accuracy: 0.527586 (0.007492) with: \"{'svc__C': 101; 'svc__kernel': 'rbf'}\"\n",
      "mean_test_accuracy: 0.974771 (0.004152) - mean_train_accuracy: 1.000000 (0.004152) with: \"{'svc__C': 102; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.451586 (0.000293) - mean_train_accuracy: 0.451586 (0.000293) with: \"{'svc__C': 102; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.529528 (0.006899) - mean_train_accuracy: 0.529935 (0.006899) with: \"{'svc__C': 102; 'svc__kernel': 'rbf'}\"\n",
      "mean_test_accuracy: 0.974771 (0.004152) - mean_train_accuracy: 1.000000 (0.004152) with: \"{'svc__C': 103; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.451586 (0.000293) - mean_train_accuracy: 0.451586 (0.000293) with: \"{'svc__C': 103; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.530796 (0.006385) - mean_train_accuracy: 0.532958 (0.006385) with: \"{'svc__C': 103; 'svc__kernel': 'rbf'}\"\n",
      "mean_test_accuracy: 0.974771 (0.004152) - mean_train_accuracy: 1.000000 (0.004152) with: \"{'svc__C': 104; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.451586 (0.000293) - mean_train_accuracy: 0.451586 (0.000293) with: \"{'svc__C': 104; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.534038 (0.006144) - mean_train_accuracy: 0.535588 (0.006144) with: \"{'svc__C': 104; 'svc__kernel': 'rbf'}\"\n",
      "mean_test_accuracy: 0.974771 (0.004152) - mean_train_accuracy: 1.000000 (0.004152) with: \"{'svc__C': 105; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.451586 (0.000293) - mean_train_accuracy: 0.451586 (0.000293) with: \"{'svc__C': 105; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.537139 (0.006825) - mean_train_accuracy: 0.538016 (0.006825) with: \"{'svc__C': 105; 'svc__kernel': 'rbf'}\"\n"
     ]
    }
   ],
   "source": [
    "means_test = resultados['mean_test_accuracy']\n",
    "std_test_acuracy = resultados['std_test_accuracy']\n",
    "means_train = resultados['mean_train_accuracy']\n",
    "std_train_acuracy = resultados['std_test_accuracy']\n",
    "params = resultados['params']\n",
    "\n",
    "for test, stdev_test, train, stdev_train, param in zip(means_test, std_test_acuracy, means_train, std_train_acuracy, params):\n",
    "    print(\"mean_test_accuracy: %f (%f) - mean_train_accuracy: %f (%f) with: %r\" %(test, stdev_test, train, stdev_train, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_test_accuracy: 0.856187 (0.051806) - mean_train_accuracy: 0.978820 (0.051806) with: \"{'svc__C': 100; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.428094 (0.011018) - mean_train_accuracy: 0.428097 (0.011018) with: \"{'svc__C': 100; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.428094 (0.011018) - mean_train_accuracy: 0.428097 (0.011018) with: \"{'svc__C': 100; 'svc__kernel': 'rbf'}\"\n",
      "mean_test_accuracy: 0.856187 (0.051806) - mean_train_accuracy: 0.978820 (0.051806) with: \"{'svc__C': 101; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.428094 (0.011018) - mean_train_accuracy: 0.428097 (0.011018) with: \"{'svc__C': 101; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.428094 (0.011018) - mean_train_accuracy: 0.428097 (0.011018) with: \"{'svc__C': 101; 'svc__kernel': 'rbf'}\"\n",
      "mean_test_accuracy: 0.856187 (0.051806) - mean_train_accuracy: 0.978820 (0.051806) with: \"{'svc__C': 102; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.428094 (0.011018) - mean_train_accuracy: 0.428097 (0.011018) with: \"{'svc__C': 102; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.428094 (0.011018) - mean_train_accuracy: 0.428097 (0.011018) with: \"{'svc__C': 102; 'svc__kernel': 'rbf'}\"\n",
      "mean_test_accuracy: 0.856187 (0.051806) - mean_train_accuracy: 0.978820 (0.051806) with: \"{'svc__C': 103; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.428094 (0.011018) - mean_train_accuracy: 0.428097 (0.011018) with: \"{'svc__C': 103; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.428094 (0.011018) - mean_train_accuracy: 0.428097 (0.011018) with: \"{'svc__C': 103; 'svc__kernel': 'rbf'}\"\n",
      "mean_test_accuracy: 0.856187 (0.051806) - mean_train_accuracy: 0.978820 (0.051806) with: \"{'svc__C': 104; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.428094 (0.011018) - mean_train_accuracy: 0.428097 (0.011018) with: \"{'svc__C': 104; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.428094 (0.011018) - mean_train_accuracy: 0.428097 (0.011018) with: \"{'svc__C': 104; 'svc__kernel': 'rbf'}\"\n",
      "mean_test_accuracy: 0.856187 (0.051806) - mean_train_accuracy: 0.978820 (0.051806) with: \"{'svc__C': 105; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.428094 (0.011018) - mean_train_accuracy: 0.428097 (0.011018) with: \"{'svc__C': 105; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.428094 (0.011018) - mean_train_accuracy: 0.428097 (0.011018) with: \"{'svc__C': 105; 'svc__kernel': 'rbf'}\"\n"
     ]
    }
   ],
   "source": [
    "resultados = pd.read_csv('resultado_pipeline_svm_CSTR.csv', sep=';')\n",
    "means_test = resultados['mean_test_accuracy']\n",
    "std_test_acuracy = resultados['std_test_accuracy']\n",
    "means_train = resultados['mean_train_accuracy']\n",
    "std_train_acuracy = resultados['std_test_accuracy']\n",
    "params = resultados['params']\n",
    "\n",
    "for test, stdev_test, train, stdev_train, param in zip(means_test, std_test_acuracy, means_train, std_train_acuracy, params):\n",
    "    print(\"mean_test_accuracy: %f (%f) - mean_train_accuracy: %f (%f) with: %r\" %(test, stdev_test, train, stdev_train, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_test_accuracy: 0.687952 (0.025410) - mean_train_accuracy: 1.000000 (0.025410) with: \"{'svc__C': 100; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.394578 (0.001237) - mean_train_accuracy: 0.394578 (0.001237) with: \"{'svc__C': 100; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.394578 (0.001237) - mean_train_accuracy: 0.394578 (0.001237) with: \"{'svc__C': 100; 'svc__kernel': 'rbf'}\"\n",
      "mean_test_accuracy: 0.687952 (0.025410) - mean_train_accuracy: 1.000000 (0.025410) with: \"{'svc__C': 101; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.394578 (0.001237) - mean_train_accuracy: 0.394578 (0.001237) with: \"{'svc__C': 101; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.394578 (0.001237) - mean_train_accuracy: 0.394578 (0.001237) with: \"{'svc__C': 101; 'svc__kernel': 'rbf'}\"\n",
      "mean_test_accuracy: 0.687952 (0.025410) - mean_train_accuracy: 1.000000 (0.025410) with: \"{'svc__C': 102; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.394578 (0.001237) - mean_train_accuracy: 0.394578 (0.001237) with: \"{'svc__C': 102; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.394578 (0.001237) - mean_train_accuracy: 0.394578 (0.001237) with: \"{'svc__C': 102; 'svc__kernel': 'rbf'}\"\n",
      "mean_test_accuracy: 0.687952 (0.025410) - mean_train_accuracy: 1.000000 (0.025410) with: \"{'svc__C': 103; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.394578 (0.001237) - mean_train_accuracy: 0.394578 (0.001237) with: \"{'svc__C': 103; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.394578 (0.001237) - mean_train_accuracy: 0.394578 (0.001237) with: \"{'svc__C': 103; 'svc__kernel': 'rbf'}\"\n",
      "mean_test_accuracy: 0.687952 (0.025410) - mean_train_accuracy: 1.000000 (0.025410) with: \"{'svc__C': 104; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.394578 (0.001237) - mean_train_accuracy: 0.394578 (0.001237) with: \"{'svc__C': 104; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.394578 (0.001237) - mean_train_accuracy: 0.394578 (0.001237) with: \"{'svc__C': 104; 'svc__kernel': 'rbf'}\"\n",
      "mean_test_accuracy: 0.687952 (0.025410) - mean_train_accuracy: 1.000000 (0.025410) with: \"{'svc__C': 105; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.394578 (0.001237) - mean_train_accuracy: 0.394578 (0.001237) with: \"{'svc__C': 105; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.394578 (0.001237) - mean_train_accuracy: 0.394578 (0.001237) with: \"{'svc__C': 105; 'svc__kernel': 'rbf'}\"\n"
     ]
    }
   ],
   "source": [
    "resultados = pd.read_csv('resultado_pipeline_svm_IrishEconomicSentiment.csv', sep=';')\n",
    "means_test = resultados['mean_test_accuracy']\n",
    "std_test_acuracy = resultados['std_test_accuracy']\n",
    "means_train = resultados['mean_train_accuracy']\n",
    "std_train_acuracy = resultados['std_test_accuracy']\n",
    "params = resultados['params']\n",
    "\n",
    "for test, stdev_test, train, stdev_train, param in zip(means_test, std_test_acuracy, means_train, std_train_acuracy, params):\n",
    "    print(\"mean_test_accuracy: %f (%f) - mean_train_accuracy: %f (%f) with: %r\" %(test, stdev_test, train, stdev_train, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_test_accuracy: 0.807750 (0.012976) - mean_train_accuracy: 1.000000 (0.012976) with: \"{'svc__C': 100; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.727750 (0.033386) - mean_train_accuracy: 0.918514 (0.033386) with: \"{'svc__C': 100; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.727375 (0.016803) - mean_train_accuracy: 0.755139 (0.016803) with: \"{'svc__C': 100; 'svc__kernel': 'rbf'}\"\n",
      "mean_test_accuracy: 0.807750 (0.012976) - mean_train_accuracy: 1.000000 (0.012976) with: \"{'svc__C': 101; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.727750 (0.033386) - mean_train_accuracy: 0.918514 (0.033386) with: \"{'svc__C': 101; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.727375 (0.016803) - mean_train_accuracy: 0.755139 (0.016803) with: \"{'svc__C': 101; 'svc__kernel': 'rbf'}\"\n",
      "mean_test_accuracy: 0.807750 (0.012976) - mean_train_accuracy: 1.000000 (0.012976) with: \"{'svc__C': 102; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.727750 (0.033386) - mean_train_accuracy: 0.918514 (0.033386) with: \"{'svc__C': 102; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.727375 (0.016803) - mean_train_accuracy: 0.755139 (0.016803) with: \"{'svc__C': 102; 'svc__kernel': 'rbf'}\"\n",
      "mean_test_accuracy: 0.807750 (0.012976) - mean_train_accuracy: 1.000000 (0.012976) with: \"{'svc__C': 103; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.727750 (0.033386) - mean_train_accuracy: 0.918514 (0.033386) with: \"{'svc__C': 103; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.727375 (0.016803) - mean_train_accuracy: 0.755139 (0.016803) with: \"{'svc__C': 103; 'svc__kernel': 'rbf'}\"\n",
      "mean_test_accuracy: 0.807750 (0.012976) - mean_train_accuracy: 1.000000 (0.012976) with: \"{'svc__C': 104; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.727750 (0.033386) - mean_train_accuracy: 0.918514 (0.033386) with: \"{'svc__C': 104; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.727375 (0.016803) - mean_train_accuracy: 0.755139 (0.016803) with: \"{'svc__C': 104; 'svc__kernel': 'rbf'}\"\n",
      "mean_test_accuracy: 0.807750 (0.012976) - mean_train_accuracy: 1.000000 (0.012976) with: \"{'svc__C': 105; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.727750 (0.033386) - mean_train_accuracy: 0.918514 (0.033386) with: \"{'svc__C': 105; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.727375 (0.016803) - mean_train_accuracy: 0.755139 (0.016803) with: \"{'svc__C': 105; 'svc__kernel': 'rbf'}\"\n"
     ]
    }
   ],
   "source": [
    "resultados = pd.read_csv('resultado_pipeline_svm_multi-domain-sentiment.csv', sep=';')\n",
    "means_test = resultados['mean_test_accuracy']\n",
    "std_test_acuracy = resultados['std_test_accuracy']\n",
    "means_train = resultados['mean_train_accuracy']\n",
    "std_train_acuracy = resultados['std_test_accuracy']\n",
    "params = resultados['params']\n",
    "\n",
    "for test, stdev_test, train, stdev_train, param in zip(means_test, std_test_acuracy, means_train, std_train_acuracy, params):\n",
    "    print(\"mean_test_accuracy: %f (%f) - mean_train_accuracy: %f (%f) with: %r\" %(test, stdev_test, train, stdev_train, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_test_accuracy: 0.825352 (0.013481) - mean_train_accuracy: 0.999926 (0.013481) with: \"{'svc__C': 100; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.133884 (0.000414) - mean_train_accuracy: 0.133884 (0.000414) with: \"{'svc__C': 100; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.432725 (0.005424) - mean_train_accuracy: 0.443420 (0.005424) with: \"{'svc__C': 100; 'svc__kernel': 'rbf'}\"\n",
      "mean_test_accuracy: 0.825352 (0.013481) - mean_train_accuracy: 0.999926 (0.013481) with: \"{'svc__C': 101; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.133884 (0.000414) - mean_train_accuracy: 0.133884 (0.000414) with: \"{'svc__C': 101; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.437096 (0.004960) - mean_train_accuracy: 0.447538 (0.004960) with: \"{'svc__C': 101; 'svc__kernel': 'rbf'}\"\n",
      "mean_test_accuracy: 0.825352 (0.013481) - mean_train_accuracy: 0.999926 (0.013481) with: \"{'svc__C': 102; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.133884 (0.000414) - mean_train_accuracy: 0.133884 (0.000414) with: \"{'svc__C': 102; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.440327 (0.004869) - mean_train_accuracy: 0.451856 (0.004869) with: \"{'svc__C': 102; 'svc__kernel': 'rbf'}\"\n",
      "mean_test_accuracy: 0.825352 (0.013481) - mean_train_accuracy: 0.999926 (0.013481) with: \"{'svc__C': 103; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.133884 (0.000414) - mean_train_accuracy: 0.133884 (0.000414) with: \"{'svc__C': 103; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.443843 (0.005662) - mean_train_accuracy: 0.455984 (0.005662) with: \"{'svc__C': 103; 'svc__kernel': 'rbf'}\"\n",
      "mean_test_accuracy: 0.825352 (0.013481) - mean_train_accuracy: 0.999926 (0.013481) with: \"{'svc__C': 104; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.133884 (0.000414) - mean_train_accuracy: 0.133884 (0.000414) with: \"{'svc__C': 104; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.448214 (0.005570) - mean_train_accuracy: 0.459553 (0.005570) with: \"{'svc__C': 104; 'svc__kernel': 'rbf'}\"\n",
      "mean_test_accuracy: 0.825352 (0.013481) - mean_train_accuracy: 0.999926 (0.013481) with: \"{'svc__C': 105; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.133884 (0.000414) - mean_train_accuracy: 0.133884 (0.000414) with: \"{'svc__C': 105; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.451254 (0.006538) - mean_train_accuracy: 0.463881 (0.006538) with: \"{'svc__C': 105; 'svc__kernel': 'rbf'}\"\n"
     ]
    }
   ],
   "source": [
    "resultados = pd.read_csv('resultado_pipeline_svm_NSF.csv', sep=';')\n",
    "means_test = resultados['mean_test_accuracy']\n",
    "std_test_acuracy = resultados['std_test_accuracy']\n",
    "means_train = resultados['mean_train_accuracy']\n",
    "std_train_acuracy = resultados['std_test_accuracy']\n",
    "params = resultados['params']\n",
    "\n",
    "for test, stdev_test, train, stdev_train, param in zip(means_test, std_test_acuracy, means_train, std_train_acuracy, params):\n",
    "    print(\"mean_test_accuracy: %f (%f) - mean_train_accuracy: %f (%f) with: %r\" %(test, stdev_test, train, stdev_train, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_test_accuracy: 0.616695 (0.017931) - mean_train_accuracy: 0.924337 (0.017931) with: \"{'svc__C': 100; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.081772 (0.001486) - mean_train_accuracy: 0.081772 (0.001486) with: \"{'svc__C': 100; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.265758 (0.011668) - mean_train_accuracy: 0.277287 (0.011668) with: \"{'svc__C': 100; 'svc__kernel': 'rbf'}\"\n",
      "mean_test_accuracy: 0.616695 (0.017931) - mean_train_accuracy: 0.924337 (0.017931) with: \"{'svc__C': 101; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.081772 (0.001486) - mean_train_accuracy: 0.081772 (0.001486) with: \"{'svc__C': 101; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.267462 (0.011326) - mean_train_accuracy: 0.279662 (0.011326) with: \"{'svc__C': 101; 'svc__kernel': 'rbf'}\"\n",
      "mean_test_accuracy: 0.616695 (0.017931) - mean_train_accuracy: 0.924354 (0.017931) with: \"{'svc__C': 102; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.081772 (0.001486) - mean_train_accuracy: 0.081772 (0.001486) with: \"{'svc__C': 102; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.271179 (0.011187) - mean_train_accuracy: 0.282088 (0.011187) with: \"{'svc__C': 102; 'svc__kernel': 'rbf'}\"\n",
      "mean_test_accuracy: 0.616695 (0.017913) - mean_train_accuracy: 0.924354 (0.017913) with: \"{'svc__C': 103; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.081772 (0.001486) - mean_train_accuracy: 0.081772 (0.001486) with: \"{'svc__C': 103; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.273811 (0.011437) - mean_train_accuracy: 0.284290 (0.011437) with: \"{'svc__C': 103; 'svc__kernel': 'rbf'}\"\n",
      "mean_test_accuracy: 0.616540 (0.018033) - mean_train_accuracy: 0.924337 (0.018033) with: \"{'svc__C': 104; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.081772 (0.001486) - mean_train_accuracy: 0.081772 (0.001486) with: \"{'svc__C': 104; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.276754 (0.010922) - mean_train_accuracy: 0.286459 (0.010922) with: \"{'svc__C': 104; 'svc__kernel': 'rbf'}\"\n",
      "mean_test_accuracy: 0.616695 (0.018003) - mean_train_accuracy: 0.924354 (0.018003) with: \"{'svc__C': 105; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.081772 (0.001486) - mean_train_accuracy: 0.081772 (0.001486) with: \"{'svc__C': 105; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.278922 (0.011443) - mean_train_accuracy: 0.288455 (0.011443) with: \"{'svc__C': 105; 'svc__kernel': 'rbf'}\"\n"
     ]
    }
   ],
   "source": [
    "resultados = pd.read_csv('resultado_pipeline_svm_Opinosis-Parsed.csv', sep=';')\n",
    "means_test = resultados['mean_test_accuracy']\n",
    "std_test_acuracy = resultados['std_test_accuracy']\n",
    "means_train = resultados['mean_train_accuracy']\n",
    "std_train_acuracy = resultados['std_test_accuracy']\n",
    "params = resultados['params']\n",
    "\n",
    "for test, stdev_test, train, stdev_train, param in zip(means_test, std_test_acuracy, means_train, std_train_acuracy, params):\n",
    "    print(\"mean_test_accuracy: %f (%f) - mean_train_accuracy: %f (%f) with: %r\" %(test, stdev_test, train, stdev_train, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_test_accuracy: 0.974068 (0.004212) - mean_train_accuracy: 0.999262 (0.004212) with: \"{'svc__C': 100; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.511207 (0.001335) - mean_train_accuracy: 0.511207 (0.001335) with: \"{'svc__C': 100; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.734949 (0.007815) - mean_train_accuracy: 0.733718 (0.007815) with: \"{'svc__C': 100; 'svc__kernel': 'rbf'}\"\n",
      "mean_test_accuracy: 0.974068 (0.004212) - mean_train_accuracy: 0.999262 (0.004212) with: \"{'svc__C': 101; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.511207 (0.001335) - mean_train_accuracy: 0.511207 (0.001335) with: \"{'svc__C': 101; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.735340 (0.007975) - mean_train_accuracy: 0.734095 (0.007975) with: \"{'svc__C': 101; 'svc__kernel': 'rbf'}\"\n",
      "mean_test_accuracy: 0.974068 (0.004212) - mean_train_accuracy: 0.999262 (0.004212) with: \"{'svc__C': 102; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.511207 (0.001335) - mean_train_accuracy: 0.511207 (0.001335) with: \"{'svc__C': 102; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.736122 (0.008337) - mean_train_accuracy: 0.734660 (0.008337) with: \"{'svc__C': 102; 'svc__kernel': 'rbf'}\"\n",
      "mean_test_accuracy: 0.974068 (0.004212) - mean_train_accuracy: 0.999262 (0.004212) with: \"{'svc__C': 103; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.511207 (0.001335) - mean_train_accuracy: 0.511207 (0.001335) with: \"{'svc__C': 103; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.736643 (0.008520) - mean_train_accuracy: 0.735094 (0.008520) with: \"{'svc__C': 103; 'svc__kernel': 'rbf'}\"\n",
      "mean_test_accuracy: 0.974068 (0.004212) - mean_train_accuracy: 0.999262 (0.004212) with: \"{'svc__C': 104; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.511207 (0.001335) - mean_train_accuracy: 0.511207 (0.001335) with: \"{'svc__C': 104; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.736643 (0.008520) - mean_train_accuracy: 0.735470 (0.008520) with: \"{'svc__C': 104; 'svc__kernel': 'rbf'}\"\n",
      "mean_test_accuracy: 0.974068 (0.004212) - mean_train_accuracy: 0.999262 (0.004212) with: \"{'svc__C': 105; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.511207 (0.001335) - mean_train_accuracy: 0.511207 (0.001335) with: \"{'svc__C': 105; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.737034 (0.008414) - mean_train_accuracy: 0.736079 (0.008414) with: \"{'svc__C': 105; 'svc__kernel': 'rbf'}\"\n"
     ]
    }
   ],
   "source": [
    "resultados = pd.read_csv('resultado_pipeline_svm_re8.csv', sep=';')\n",
    "means_test = resultados['mean_test_accuracy']\n",
    "std_test_acuracy = resultados['std_test_accuracy']\n",
    "means_train = resultados['mean_train_accuracy']\n",
    "std_train_acuracy = resultados['std_test_accuracy']\n",
    "params = resultados['params']\n",
    "\n",
    "for test, stdev_test, train, stdev_train, param in zip(means_test, std_test_acuracy, means_train, std_train_acuracy, params):\n",
    "    print(\"mean_test_accuracy: %f (%f) - mean_train_accuracy: %f (%f) with: %r\" %(test, stdev_test, train, stdev_train, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_test_accuracy: 0.860500 (0.026688) - mean_train_accuracy: 1.000000 (0.026688) with: \"{'svc__C': 100; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.739500 (0.027609) - mean_train_accuracy: 0.873000 (0.027609) with: \"{'svc__C': 100; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.757000 (0.027404) - mean_train_accuracy: 0.842222 (0.027404) with: \"{'svc__C': 100; 'svc__kernel': 'rbf'}\"\n",
      "mean_test_accuracy: 0.860500 (0.026688) - mean_train_accuracy: 1.000000 (0.026688) with: \"{'svc__C': 101; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.739500 (0.027609) - mean_train_accuracy: 0.873000 (0.027609) with: \"{'svc__C': 101; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.757000 (0.027404) - mean_train_accuracy: 0.842222 (0.027404) with: \"{'svc__C': 101; 'svc__kernel': 'rbf'}\"\n",
      "mean_test_accuracy: 0.860500 (0.026688) - mean_train_accuracy: 1.000000 (0.026688) with: \"{'svc__C': 102; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.739500 (0.027609) - mean_train_accuracy: 0.873000 (0.027609) with: \"{'svc__C': 102; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.757000 (0.027404) - mean_train_accuracy: 0.842222 (0.027404) with: \"{'svc__C': 102; 'svc__kernel': 'rbf'}\"\n",
      "mean_test_accuracy: 0.860500 (0.026688) - mean_train_accuracy: 1.000000 (0.026688) with: \"{'svc__C': 103; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.739500 (0.027609) - mean_train_accuracy: 0.873000 (0.027609) with: \"{'svc__C': 103; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.757000 (0.027404) - mean_train_accuracy: 0.842222 (0.027404) with: \"{'svc__C': 103; 'svc__kernel': 'rbf'}\"\n",
      "mean_test_accuracy: 0.860500 (0.026688) - mean_train_accuracy: 1.000000 (0.026688) with: \"{'svc__C': 104; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.739500 (0.027609) - mean_train_accuracy: 0.873000 (0.027609) with: \"{'svc__C': 104; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.757000 (0.027404) - mean_train_accuracy: 0.842222 (0.027404) with: \"{'svc__C': 104; 'svc__kernel': 'rbf'}\"\n",
      "mean_test_accuracy: 0.860500 (0.026688) - mean_train_accuracy: 1.000000 (0.026688) with: \"{'svc__C': 105; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.739500 (0.027609) - mean_train_accuracy: 0.873000 (0.027609) with: \"{'svc__C': 105; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.757000 (0.027404) - mean_train_accuracy: 0.842222 (0.027404) with: \"{'svc__C': 105; 'svc__kernel': 'rbf'}\"\n"
     ]
    }
   ],
   "source": [
    "resultados = pd.read_csv('resultado_pipeline_svm_review_polarity.csv', sep=';')\n",
    "means_test = resultados['mean_test_accuracy']\n",
    "std_test_acuracy = resultados['std_test_accuracy']\n",
    "means_train = resultados['mean_train_accuracy']\n",
    "std_train_acuracy = resultados['std_test_accuracy']\n",
    "params = resultados['params']\n",
    "\n",
    "for test, stdev_test, train, stdev_train, param in zip(means_test, std_test_acuracy, means_train, std_train_acuracy, params):\n",
    "    print(\"mean_test_accuracy: %f (%f) - mean_train_accuracy: %f (%f) with: %r\" %(test, stdev_test, train, stdev_train, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_test_accuracy: 0.964119 (0.006582) - mean_train_accuracy: 1.000000 (0.006582) with: \"{'svc__C': 100; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.341116 (0.000772) - mean_train_accuracy: 0.341116 (0.000772) with: \"{'svc__C': 100; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.371099 (0.007168) - mean_train_accuracy: 0.371672 (0.007168) with: \"{'svc__C': 100; 'svc__kernel': 'rbf'}\"\n",
      "mean_test_accuracy: 0.964119 (0.006582) - mean_train_accuracy: 1.000000 (0.006582) with: \"{'svc__C': 101; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.341116 (0.000772) - mean_train_accuracy: 0.341116 (0.000772) with: \"{'svc__C': 101; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.372573 (0.007264) - mean_train_accuracy: 0.373147 (0.007264) with: \"{'svc__C': 101; 'svc__kernel': 'rbf'}\"\n",
      "mean_test_accuracy: 0.964119 (0.006582) - mean_train_accuracy: 1.000000 (0.006582) with: \"{'svc__C': 102; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.341116 (0.000772) - mean_train_accuracy: 0.341116 (0.000772) with: \"{'svc__C': 102; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.374539 (0.006132) - mean_train_accuracy: 0.375058 (0.006132) with: \"{'svc__C': 102; 'svc__kernel': 'rbf'}\"\n",
      "mean_test_accuracy: 0.964119 (0.006582) - mean_train_accuracy: 1.000000 (0.006582) with: \"{'svc__C': 103; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.341116 (0.000772) - mean_train_accuracy: 0.341116 (0.000772) with: \"{'svc__C': 103; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.376751 (0.006765) - mean_train_accuracy: 0.376587 (0.006765) with: \"{'svc__C': 103; 'svc__kernel': 'rbf'}\"\n",
      "mean_test_accuracy: 0.964119 (0.006582) - mean_train_accuracy: 1.000000 (0.006582) with: \"{'svc__C': 104; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.341116 (0.000772) - mean_train_accuracy: 0.341116 (0.000772) with: \"{'svc__C': 104; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.377980 (0.006068) - mean_train_accuracy: 0.378526 (0.006068) with: \"{'svc__C': 104; 'svc__kernel': 'rbf'}\"\n",
      "mean_test_accuracy: 0.964119 (0.006582) - mean_train_accuracy: 1.000000 (0.006582) with: \"{'svc__C': 105; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.341116 (0.000772) - mean_train_accuracy: 0.341116 (0.000772) with: \"{'svc__C': 105; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.381175 (0.005659) - mean_train_accuracy: 0.380438 (0.005659) with: \"{'svc__C': 105; 'svc__kernel': 'rbf'}\"\n"
     ]
    }
   ],
   "source": [
    "resultados = pd.read_csv('resultado_pipeline_svm_Reviews.csv', sep=';')\n",
    "means_test = resultados['mean_test_accuracy']\n",
    "std_test_acuracy = resultados['std_test_accuracy']\n",
    "means_train = resultados['mean_train_accuracy']\n",
    "std_train_acuracy = resultados['std_test_accuracy']\n",
    "params = resultados['params']\n",
    "\n",
    "for test, stdev_test, train, stdev_train, param in zip(means_test, std_test_acuracy, means_train, std_train_acuracy, params):\n",
    "    print(\"mean_test_accuracy: %f (%f) - mean_train_accuracy: %f (%f) with: %r\" %(test, stdev_test, train, stdev_train, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_test_accuracy: 0.916168 (0.055423) - mean_train_accuracy: 0.994675 (0.055423) with: \"{'svc__C': 100; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.410180 (0.009664) - mean_train_accuracy: 0.410182 (0.009664) with: \"{'svc__C': 100; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.410180 (0.009664) - mean_train_accuracy: 0.410182 (0.009664) with: \"{'svc__C': 100; 'svc__kernel': 'rbf'}\"\n",
      "mean_test_accuracy: 0.916168 (0.055423) - mean_train_accuracy: 0.994675 (0.055423) with: \"{'svc__C': 101; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.410180 (0.009664) - mean_train_accuracy: 0.410182 (0.009664) with: \"{'svc__C': 101; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.410180 (0.009664) - mean_train_accuracy: 0.410182 (0.009664) with: \"{'svc__C': 101; 'svc__kernel': 'rbf'}\"\n",
      "mean_test_accuracy: 0.916168 (0.055423) - mean_train_accuracy: 0.994675 (0.055423) with: \"{'svc__C': 102; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.410180 (0.009664) - mean_train_accuracy: 0.410182 (0.009664) with: \"{'svc__C': 102; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.410180 (0.009664) - mean_train_accuracy: 0.410182 (0.009664) with: \"{'svc__C': 102; 'svc__kernel': 'rbf'}\"\n",
      "mean_test_accuracy: 0.916168 (0.055423) - mean_train_accuracy: 0.994675 (0.055423) with: \"{'svc__C': 103; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.410180 (0.009664) - mean_train_accuracy: 0.410182 (0.009664) with: \"{'svc__C': 103; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.410180 (0.009664) - mean_train_accuracy: 0.410182 (0.009664) with: \"{'svc__C': 103; 'svc__kernel': 'rbf'}\"\n",
      "mean_test_accuracy: 0.916168 (0.055423) - mean_train_accuracy: 0.994675 (0.055423) with: \"{'svc__C': 104; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.410180 (0.009664) - mean_train_accuracy: 0.410182 (0.009664) with: \"{'svc__C': 104; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.410180 (0.009664) - mean_train_accuracy: 0.410182 (0.009664) with: \"{'svc__C': 104; 'svc__kernel': 'rbf'}\"\n",
      "mean_test_accuracy: 0.916168 (0.055423) - mean_train_accuracy: 0.994675 (0.055423) with: \"{'svc__C': 105; 'svc__kernel': 'linear'}\"\n",
      "mean_test_accuracy: 0.410180 (0.009664) - mean_train_accuracy: 0.410182 (0.009664) with: \"{'svc__C': 105; 'svc__kernel': 'poly'}\"\n",
      "mean_test_accuracy: 0.410180 (0.009664) - mean_train_accuracy: 0.410182 (0.009664) with: \"{'svc__C': 105; 'svc__kernel': 'rbf'}\"\n"
     ]
    }
   ],
   "source": [
    "resultados = pd.read_csv('resultado_pipeline_svm_Syskillwebert-Parsed.csv', sep=';')\n",
    "means_test = resultados['mean_test_accuracy']\n",
    "std_test_acuracy = resultados['std_test_accuracy']\n",
    "means_train = resultados['mean_train_accuracy']\n",
    "std_train_acuracy = resultados['std_test_accuracy']\n",
    "params = resultados['params']\n",
    "\n",
    "for test, stdev_test, train, stdev_train, param in zip(means_test, std_test_acuracy, means_train, std_train_acuracy, params):\n",
    "    print(\"mean_test_accuracy: %f (%f) - mean_train_accuracy: %f (%f) with: %r\" %(test, stdev_test, train, stdev_train, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
